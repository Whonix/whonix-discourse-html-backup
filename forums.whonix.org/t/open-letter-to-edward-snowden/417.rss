<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>Open letter to Edward Snowden</title>
    <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417</link>
    <description>[html]&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Y-0OWM3YB54&amp;feature&amp;t=45m0s&quot;&gt;At HopeX conference, Edward Snowden encouraged those who have heard of Tor, Tails, Whonix, and Linux to defend Internet liberties.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thank you Edward Snowden for the attention, the motivating words and your continued activism.&lt;/p&gt;
&lt;p&gt;It is a shame, that you are not getting asylum in Germany. Needless to say, that I oppose the cowardice of my government and the gibberish they are talking.&lt;/p&gt;
&lt;p&gt;There are lots of &lt;a href=&quot;http://en.wikipedia.org/wiki/List_of_United_States_Army_installations_in_Germany&quot;&gt;US military bases in Germany&lt;/a&gt;. I am not sure they would not be coming for you if you were in Germany. And I am quite sure, they would not leave if they were asked to leave. Nevertheless, it should be official policy for Germany to ask US military to leave.&lt;/p&gt;
&lt;p&gt;I am not against the people in the US. In fact, people from the US are supporting Whonix.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.volksentscheid.de/emnid-umfrage-volksabstimmungen.html&quot;&gt;87 % of Germans want plebiscite.&lt;/a&gt; &lt;a href=&quot;http://deutsche-wirtschafts-nachrichten.de/2014/05/01/umfrage-deutsche-lehnen-militaer-aktion-in-der-ukraine-ab/&quot;&gt;Only 16% want military in Ukraine.&lt;/a&gt; (Still too much, but majority is sane.)&lt;/p&gt;
&lt;p&gt;Even if there are vast opposing majorities, our government somehow manages to ignore the will of the People without consequences.&lt;/p&gt;
&lt;p&gt;Hopefully the people figure out how to end this insanity. I don’t want world war 3.&lt;/p&gt;
&lt;p&gt;I extend an open invitation: I’d be honored by any advice or discussion – on-topic or off-topic.&lt;/p&gt;
&lt;p&gt;Off-topic, especially what know about extraterrestrials would be most interesting.&lt;/p&gt;
&lt;p&gt;Thank you again, Edward Snowden!&lt;/p&gt;
&lt;p&gt;Forum discussion on this topic:

&lt;a href=&quot;https://www.whonix.org/forum/index.php/topic,437.0/topicseen.html&quot;&gt;https://www.whonix.org/forum/index.php/topic,437.0/topicseen.html&lt;/a&gt;&lt;/p&gt;
[/html]</description>
    <language>en</language>
    <lastBuildDate>Wed, 22 Oct 2014 15:28:27 +0000</lastBuildDate>
    <category>News</category>
    <atom:link href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Dennis]]></dc:creator>
        <description><![CDATA[
            <p>Extraterrestrials! Just show me one and I’ll believe. <img src="//forums.whonix.org/images/emoji/twitter/slight_smile.png?v=5" title=":slight_smile:" class="emoji" alt=":slight_smile:"> Until then, I’m inclined to dismiss the possibility.</p>
<p>The Fermi Paradox is a big problem. If they’re out there, why don’t we see them? In particular, given the age of the visible universe according to Big Bang theory, they should have had ample time not only to evolve well before us but to have colonized every habitable planet - which means that we shouldn’t be here. But we are here and they (evidently) aren’t (and if they are, then show me one).</p>
<p>Now consider the Rare Earth hypothesis, which, to my mind, is at least free of any obvious self-contradiction: That, because of chance, the conditions of the solar system are very, very special in being suited to the emergence of tool-using, intelligent life. the other side of the hypothesis is that somewhat terrestrial planets (such as Mars) inhabited by bacteria (because they are so amazingly tough) are ubiquitous. That’s good news if we are the only technological species, since we have a universe of planets for us to terraform and settle on.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/34">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/34</link>
        <pubDate>Wed, 22 Oct 2014 15:28:27 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-34</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Dennis]]></dc:creator>
        <description><![CDATA[
            <p>The war on terror is a fraud, and therefore “distributed evil” can probably be dismissed as more than a minor concern for the world of the future.</p>
<p>It is well documented that:</p>
<ol>
<li>
<p>Most FBI convictions of alleged terrorists result from “sting” operations where the agents persuade some idiots to do something stupid, by giving them fake bombs and so on.</p>
</li>
<li>
<p>The official account of 9/11 (i.e., the official conspiracy theory) falls apart upon close examination.</p>
</li>
<li>
<p>The violence and deaths that result from the market in contraband goods is an artifact of those goods’ prohibition. Note, for example, the drop in narcotic drug use in Portugal after decriminalization, and the lower crime rates in US states that have more liberal gun laws.</p>
</li>
</ol>
<p>Without the state, evil people will only be able to do damage on a small scale, and can be defended against by individuals or local communities.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/33">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/33</link>
        <pubDate>Wed, 22 Oct 2014 15:13:41 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-33</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Dennis]]></dc:creator>
        <description><![CDATA[
            <p>And yet, remarkably little information from the supposed “leaks” has actually been published.</p>
<p>My tentative conclusion about Snowden is that he is a patsy (willing or unknowing) for the CIA in its rivalry with the NSA.</p>
<p>Now, considering Wikileaks: Their leaking is somewhat selective, the big omission being anything embarrassing about the US-Israel relationship. So I don’t take Assange any more seriously than Snowden.</p>
<p>What, then, might be the purpose of the Snowden affair or Wikileaks if they don’t actually reveal anything that would embarrass certain major interests? Perhaps the point is to let us know that we are being watched and to mind what we say or do, like the prisoners in the Panopticon who dare not break the prison’s rules because they are not sure whether the guards can see them.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/32">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/32</link>
        <pubDate>Wed, 22 Oct 2014 15:02:24 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-32</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Michael]]></dc:creator>
        <description><![CDATA[
            <p>[quote=“gh0st, post:30, topic:417”]I was simply reassuring you that Patrick provided technical examples in that regard, because you requested so much.</p>
<p>Nobody is taking it personally</p>
<p>(btw edited above post a little to respond to some of your points in response to patrick)[/quote]</p>
<p>Cool gh0st…</p>
<p>Glad that’s resolved.</p>
<p>I have enjoyed multiple perspectives you’ve brought up thus far. <img src="//forums.whonix.org/images/emoji/twitter/smiley.png?v=5" title=":smiley:" class="emoji" alt=":smiley:"></p>
<p>You seem to believe in the spirit of human potential and that’s a really good thing!</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/31">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/31</link>
        <pubDate>Wed, 20 Aug 2014 06:55:32 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-31</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[gh0st66]]></dc:creator>
        <description><![CDATA[
            <p>I was simply reassuring you that Patrick provided technical examples in that regard, because you requested so much.</p>
<p>Nobody is taking it personally</p>
<p>(btw edited above post a little to respond to some of your points in response to patrick)</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/30">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/30</link>
        <pubDate>Wed, 20 Aug 2014 06:40:22 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-30</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Michael]]></dc:creator>
        <description><![CDATA[
            <aside class="quote" data-post="28" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>Majority of my posts were not nearly as long as yours, lol.</p>
</blockquote>
</aside>
<p>Yes. I am “verbose” in my thinking and writing. Just how I generally am.</p>
<p>But what’s wrong with fleshing out and sharing “detail”, especially on complex unresolved matters in life?</p>
<p>It often takes centuries filled with deeply technical book volumes for humanity to master subjects.</p>
<p>A handful of “long” forum posts, which are optional to read and respond to, doesn’t seem like such a big deal to me.</p>
<aside class="quote" data-post="28" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>Patrick then seemed to provide nice real world examples along the same lines as this. So you can now have more detailed potential “technical” answers to your questions…</p>
</blockquote>
</aside>
<p>Thanks gh0st. Yes, I’ve seen and responded with my thoughts to Patrick’s most recent post.</p>
<p>–</p>
<p>gh0st you officially win this “social tussle” going on, okay.</p>
<p>We don’t need to keep critiquing past “he said, she said” stuff. Let’s just move on.</p>
<p>If anything further of intellectual interest comes up, we can share our thoughts, with an understanding that all of this communication is voluntary, pseudo-anonymous, and not to be taken personally.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/29">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/29</link>
        <pubDate>Wed, 20 Aug 2014 06:36:46 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-29</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[gh0st66]]></dc:creator>
        <description><![CDATA[
            <p>Majority of my posts were not nearly as long as yours, lol. Anyways before I took a tangent on potentially exploring neighbors in the universe for helpful solutions</p>
<p>I kept by my original explanation which is this earlier post <a href="https://www.whonix.org/forum/index.php/topic,437.msg3413.html#msg3413" rel="nofollow noopener">https://www.whonix.org/forum/index.php/topic,437.msg3413.html#msg3413</a></p>
<p>Patrick then seemed to provide nice real world examples along the same lines as this. So you can now have more detailed potential “technical” answers to your questions… Although Patrick did note that the human mind doesn’t even need such a high degree of advancement to potentially work out a solution</p>
<p>EDIT: also in regards to implementing a solution like this, it would just have to take advantage of human nature as I outlined previously. Just take computer chips for example. Literally just about everyone who owns a computer uses hardware that they don’t necessarily know everything that is inside it and how it functions. Yet probably 90% of PC owners use it because the benefit outweighs the risks.</p>
<p>ultimately you are right in that this is a chicken and egg solution and this is just the circle of life. That is why the only way to actually completely eradicate the chicken and egg problem, we will need a “miracle” solution as I mentioned above.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/28">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/28</link>
        <pubDate>Wed, 20 Aug 2014 06:21:28 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-28</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Michael]]></dc:creator>
        <description><![CDATA[
            <aside class="quote" data-post="25" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>Maybe you should be asking yourself why you feel the need to make such long posts trying to critique a vague idea of mine (I admit it is vague lol… so?) It was simply a tangent I took in regards to understanding and advancing the human mind as the source of a potential solution. lol.</p>
</blockquote>
</aside>
<p>Probably a mixture of whatever drove you to respond to my posts.</p>
<p>Plus a real personal passion / interest in the subject matter that I have, along with a real hunger to find viable solutions.</p>
<p>gh0st, we’re on the same side here.</p>
<p>Truce. BFFs. <img src="//forums.whonix.org/images/emoji/twitter/stuck_out_tongue.png?v=5" title=":stuck_out_tongue:" class="emoji" alt=":stuck_out_tongue:"></p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/27">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/27</link>
        <pubDate>Wed, 20 Aug 2014 06:08:05 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-27</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Michael]]></dc:creator>
        <description><![CDATA[
            <aside class="quote" data-post="22" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/user_avatar/forums.whonix.org/patrick/40/17_1.png" class="avatar"> Patrick:</div>
<blockquote>
<p>I think ETs either fixed all their mental health problems so no one risks destruction of their whole race (more likely: would match existing common claims about ETs) or they’re using a system of total enslavement (total surveillance, mind control devices, maybe borg like) with a centralist power (less likely).</p>
</blockquote>
</aside>
<p>Agreed. But it likely has to be TOTAL across the entire species.</p>
<p>And any biological (likely emotional) species of any meaningful size is likely to have at least a minority, or more, of its population disagree and fight back against any alteration of their individual brain biology.</p>
<p>And so it could very likely be a state of “waring competition” of great destruction upfront, before a singular/united/centralist power ultimately wins out, gives itself a power advantage, and imposes its species wide control and security solutions. Whatever those specifics may be.</p>
<p>No matter what the species, I see that basic scenario likely playing out for any population of independently willed and powerful entities.</p>
<aside class="quote" data-post="22" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/user_avatar/forums.whonix.org/patrick/40/17_1.png" class="avatar"> Patrick:</div>
<blockquote>
<p>Most likely humans won’t receive help from ETs and most likely there is also no higher power that intervenes in human affairs.</p>
</blockquote>
</aside>
<p>Unfortunately true.</p>
<aside class="quote" data-post="22" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/user_avatar/forums.whonix.org/patrick/40/17_1.png" class="avatar"> Patrick:</div>
<blockquote>
<p>Unfortunately, most likely human race will extinct itself with super technology before science progresses to deeply understand and “heal” human mind. I elaborate on “heal” later. “heal” assumes here, that there is no free will and that all evil actions can be isolated to a physical issue.</p>
</blockquote>
</aside>
<p>Unfortunately true.</p>
<aside class="quote" data-post="22" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/user_avatar/forums.whonix.org/patrick/40/17_1.png" class="avatar"> Patrick:</div>
<blockquote>
<p>Most likely there is no free will. Or at least that mindset will spread. Either we continue to act as if we had free will and/or at least scientists / policy makers / doctors / courts might adapt to the new paradigm.</p>
</blockquote>
</aside>
<p>As we look deeper into the physical brain to understand our consciousness, we will likely find nothing physically special from other mechanical bits of the inanimate (molecules, atoms, quarks, etc).</p>
<p>There’s always logical philosophical possibilities that exist beyond our tangible data/experiences.</p>
<p>But it all (we all) could just be biological robots who are carrying out entropic reactions of mere colliding bits matter.</p>
<p>Our seeming sense of order, intelligence, consciousness, and cross-entity awareness between all of us is a peculiar feature, if we are pure physical machines with no consciously directed free will.</p>
<aside class="quote" data-post="22" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/user_avatar/forums.whonix.org/patrick/40/17_1.png" class="avatar"> Patrick:</div>
<blockquote>
<p>Let’s extrapolate from there. Maybe there will be no technological or physical barriers calculating what a brain will do. I could imagine, that science may at some point be able to totally understand the brain. Being able to read thoughts. Make the behavior of the brain totally predictable, so at some point you could read on some screen what someone will think, say, do within the next minutes [unless X happens etc.].</p>
</blockquote>
</aside>
<p>Yes, this is a technologically sound extrapolation.</p>
<p>[quote=“Patrick, post:22, topic:417”]When we are at this point, we would literally understand the evil parts of human nature. Maybe those can all be broken down pointing to some kind of illness that might be curable. If evolution is true (probably is), it is unlikely that evolution has produced “real evil”. We could get to a “all actions are positively motivated” paradigm. “Evil” could be seen as best as a byproduct that survived evolution that has no intention of its own. Maybe we’ll be able to isolate all the evil / flawed parts that produce irrationality, anger [ex: broken hormone release, imbalance], hatred [ex: constrict vein], violence [ex: miniature tumor] and so forth in any brain and be able to heal them. Just like a computer there is only a limited amount of things that can break and with enough effort all issues can be diagnoses and reliably fixed. A brain is much more complex than a computer, but perhaps conceptually it is the same.</p>
<p>In such a future with brain health scanners everywhere it could be possible that humanity survives peacefully in the age of super technology and that even freedom is provided to individuals.[/quote]</p>
<p>Possible. Kind of a “chicken and egg” problem of getting there, though.</p>
<p>Since raw technology is agnostic, and without squashing all the “evil” of humans, and taking out any malicious automated drones / AIs that have been released, then such advanced technological capabilities will also be used to pursue other objectives than globally enforced health/security policies (such as: ideological or other evil destruction, libertarian independence, etc).</p>
<p>Me, personally, I wouldn’t want to accept any heavily invasive third party regime over my body/life. I’d probably seek to use advanced technology to fight off such benevolent overloads to remain independent and free as an individual being.</p>
<p>Same reason I use Tor, Whonix, open source, etc, instead of centrally policed digital tools. I’ll never fully trust third parties. I go more and more towards independently robust solutions to living and securing my own life. The more power technology affords me to do so, the more I will seize and defend that power for my own independent existence.</p>
<p>I’m not an evil soul, but, would certainly defend, with superpower violence, my right to remain independent of any global regime/force. I don’t care if it is intelligent, benevolent, and accepted by mainstream norms. So, personally, I’d feel untrusting or hostile towards any centralized power over my life, even if it is what can best save humanity. Yet, it would be ideal (for any individual) to have the rest of humanity safely contained, but have their own freedom unhampered. Thus, even beyond “evil”, there is the intertwined self-interested competition for power / independence / security.</p>
<p>Even for AIs with non-emotional independent objectives, this non-evil-based competition is still a major factor for inter-AI interactions and decisions of power / independence / security, for asserting themselves to acheive more optimal outcomes for whatever objectives they are programmed with.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/26">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/26</link>
        <pubDate>Wed, 20 Aug 2014 06:03:31 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-26</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[gh0st66]]></dc:creator>
        <description><![CDATA[
            <p>Maybe you should be asking yourself why you feel the need to make such long posts trying to critique a vague idea of mine (I admit it is vague lol… so?) It was simply a tangent I took after this post <a href="https://www.whonix.org/forum/index.php/topic,437.msg3413.html#msg3413" rel="nofollow noopener">https://www.whonix.org/forum/index.php/topic,437.msg3413.html#msg3413</a> in regards to understanding and advancing the human mind as the source of a potential solution. lol. Patrick put the subject of advancing the the mind into real world examples.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/25">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/25</link>
        <pubDate>Wed, 20 Aug 2014 06:02:44 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-25</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Michael]]></dc:creator>
        <description><![CDATA[
            <aside class="quote" data-post="21" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>Anyways, all I am proposing is a larger scale approach that follows what Einstein stated "We can not solve our problems with the same level of thinking that created them”.</p>
</blockquote>
</aside>
<p>Ok. I see no problems with humanity pursuing that avenue.</p>
<p>It was the “unified parent(s) vs. child” “sandbox” outcome that I see pitfalls with.</p>
<p>It’s logically hard to have faith that the parents will be unified and that the children won’t be capable of destroying the sandbox.</p>
<aside class="quote" data-post="21" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>I see you like to repeat 1000x often lol. This number was used as an example of a high number so that you can grasp a higher level of the meaning “advanced” consciousness / intellect</p>
</blockquote>
</aside>
<p>LOL! <img src="//forums.whonix.org/images/emoji/twitter/smiley.png?v=5" title=":smiley:" class="emoji" alt=":smiley:"></p>
<p>Yeah, I understand what you meant by using “1000X”. I just thought it was a useful communication tool you used and was accepting it and using it with you in return.</p>
<p>100X, 500X, 1000X, 5000X, 10000X, doesn’t really matter.</p>
<p>The underlying concept is a “power disparity” that creates a far superior advantage.</p>
<aside class="quote" data-post="21" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>What you don’t seem to grasp is the fact that with this proposed solution, a child will not understand the approach of a parent. It is like trying to grasp the idea of the internet before it was invented. Which is now being used by virtually everyone on the planet.</p>
</blockquote>
</aside>
<p>If a human invention, then if one person can understand it well enough to invent it, then most highly intelligent people can understand it as well (if laid out in logical procedural detail).</p>
<p>If it comes from human AI, then that AI/software can and will likely be copied, and we all become competitive AI superpowers.</p>
<p>What is suspect is whether a vastly superior, non-shared/non-distributed, intelligence will come along any time soon in the upcoming decades (21st century).</p>
<p>If it does, then you are right and we could/will all be children by comparison.</p>
<p>So this “solution” relies upon an extremely remote possibility occurring first, which you yourself admit you can’t gauge any real likelihood of occurring.</p>
<aside class="quote" data-post="21" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>Global issues are a recurring theme that has been repeating through history because of the flaws of human nature. Do you really think that the solution to HUMANITY, would be something ordinary that your primitive mind can easily conceive and grasp? (not you specifically, referring to all of us)</p>
</blockquote>
</aside>
<p>Nope. I agree with that notion.</p>
<p>It is just highly skeptical that this solution will actually come to fruition.</p>
<p>You’re on the side of having faith in something that has never existed before that has power lightyears beyond imagination.</p>
<p>And it all needs to happen very soon (within decades).</p>
<p>Classic faith-based optimism. But it’s your right to have such optimistic faith though.</p>
<p>It just doesn’t translate down to transferable logic in the details without strong evidence to support it.</p>
<p>Quoting a vague colloquialism that Einstein said is not a strong basis for taking a possibility on likely faith.</p>
<p>Many of your arguments pre-suppose that the solution just somehow, without explanation, overcomes all barriers and challenges and then sustainably works indefinitely from then on.</p>
<p>In my opinion, no answer is beyond technical question. Even if invented by super intelligence.</p>
<p>In principle, if the remote possibility of what you’re proposing happens, and it is robustly bulletproof against all indefinite natural entropy, technical hacking, and power competition, then… fine, you’ll have been proven correct.</p>
<aside class="quote" data-post="21" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>Never did I only ask for positive encouragement so I don’t know why you are acting as though I am. For the sake of everyone, it would be better if I didn’t have to literally quote myself again for you, just so that you read it well enough, then maybe you can do a better job at responding with proper assessment… just some advice.</p>
</blockquote>
</aside>
<p>Correct, you did not ask for it. However, you didn’t seem to like me logically challenging your proposed solution. And you’ve been talking about “encouragement”, “anti-cynicism”, and “optimism” and quoting inspirational figures and stories from mainstream culture.</p>
<p>Personally, I’m just primarily after technical truth and solutions and am trying to gauge the real world viability of such things.</p>
<p>All the social and emotional stuff takes a back seat compared to the soundness of logical concepts presented (for me at least).</p>
<p>You’re the one who brought these aspects of personality up, so I was assuming that based on you doing so, maybe you were not looking to have your proposed solution critiqued for its viability as a likely solution, but rather just have others be okay with it being “possible” and not question it any further.</p>
<p>Yes, gh0st, it is a possible theory you proposed.</p>
<p>As a viable real world solution, it has a lot left to be desired.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/24">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/24</link>
        <pubDate>Wed, 20 Aug 2014 05:12:59 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-24</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[gh0st66]]></dc:creator>
        <description><![CDATA[
            <p>True, this is indeed all very speculative.</p>
<p>you outlined some good real world examples how the study of the mind can be turned into a potential solution</p>
<p>We definitely need to put more resources into studying the human mind, as I mentioned in an earlier post with similar points on maintaining peace <a href="https://www.whonix.org/forum/index.php/topic,437.msg3413.html#msg3413" rel="nofollow noopener">https://www.whonix.org/forum/index.php/topic,437.msg3413.html#msg3413</a></p>
<blockquote>The evil in humans is almost as much of a sickness as any other mental illness.</blockquote>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/23">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/23</link>
        <pubDate>Wed, 20 Aug 2014 04:05:39 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-23</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Patrick]]></dc:creator>
        <description><![CDATA[
            <p>This whole post is very speculative. I wouldn’t dare to claim any kind of certainty on these matters.</p>
<hr>
<p>If any claims of ETs have on in common: they’re all biological. Good indication, that they failed yet to implement a strong AI or fixed theirs brains so no one is attempting to develop one.</p>
<p>I think ETs either fixed all their mental health problems so no one risks destruction of their whole race (more likely: would match existing common claims about ETs) or they’re using a system of total enslavement (total surveillance, mind control devices, maybe borg like) with a centralist power (less likely).</p>
<hr>
<p>Most likely humans won’t receive help from ETs and most likely there is also no higher power that intervenes in human affairs.</p>
<p>Unfortunately, most likely human race will extinct itself with super technology before science progresses to deeply understand and “heal” human mind. I elaborate on “heal” later. “heal” assumes here, that there is no free will and that all evil actions can be isolated to a physical issue.</p>
<hr>
<p>One source, podium discussion about consciousness: <a href="https://www.youtube.com/watch?v=y7RL__ZgdEw">https://www.youtube.com/watch?v=y7RL__ZgdEw</a></p>
<p>Good intro on (non-)free will: <a href="https://www.youtube.com/watch?v=_FanhvXO9Pk">https://www.youtube.com/watch?v=_FanhvXO9Pk</a></p>
<p>Most likely there is no free will. Or at least that mindset will spread. Either we continue to act as if we had free will and/or at least scientists / policy makers / doctors / courts might adapt to the new paradigm.</p>
<p>Science is at the very beginning of really understanding the mind.</p>
<ul>
<li>They can already tell when you will decide for what option before you’re aware of it. (“no free will”)</li>
<li>They can screen for sociopaths by showing them horrible material and their brain not reacting as “normal” (whatever that is). (“detect “evil””)</li>
<li>Know which selected youtube video you are watching depending on the pattern in your brain. (“read thoughts”)</li>
</ul>
<p>Let’s extrapolate from there. Maybe there will be no technological or physical barriers calculating what a brain will do. I could imagine, that science may at some point be able to totally understand the brain. Being able to read thoughts. Make the behavior of the brain totally predictable, so at some point you could read on some screen what someone will think, say, do within the next minutes [unless X happens etc.].</p>
<p>When we are at this point, we would literally understand the evil parts of human nature. Maybe those can all be broken down pointing to some kind of illness that might be curable. If evolution is true (probably is), it is unlikely that evolution has produced “real evil”. We could get to a “all actions are positively motivated” paradigm. “Evil” could be seen as best as a byproduct that survived evolution that has no intention of its own. Maybe we’ll be able to isolate all the evil / flawed parts that produce irrationality, anger [ex: broken hormone release, imbalance], hatred [ex: constrict vein], violence [ex: miniature tumor] and so forth in any brain and be able to heal them. Just like a computer there is only a limited amount of things that can break and with enough effort all issues can be diagnoses and reliably fixed. A brain is much more complex than a computer, but perhaps conceptually it is the same.</p>
<p>In such a future with brain health scanners everywhere it could be possible that humanity survives peacefully in the age of super technology and that even freedom is provided to individuals.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/22">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/22</link>
        <pubDate>Wed, 20 Aug 2014 03:51:17 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-22</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[gh0st66]]></dc:creator>
        <description><![CDATA[
            <p>Your are right in that, Elon Musk may have not been as good of an example in that context, as much as the “likelihood” of the achievements made for humanity by Nikola Tesla. Which, let me remind you, is merely a small scale example of how you look at “likelihood”</p>
<p>Anyways, all I am proposing is a larger scale approach that follows what Einstein stated "We can not solve our problems with the same level of thinking that created them”.</p>
<p>[quote=“Michael, post:20, topic:417”]Likely relative to… equally matched (no 1000X disparity advantage) humans perpetuating human violence here on Earth.</p>
<p>Because without a miracle source of almighty 1000X contained intelligence coming out of left field, that’s the “default” scenario we will practically have to deal with.[/quote]</p>
<p>I see you like to repeat 1000x often lol. This number was used as an example of a high number so that you can grasp a higher level of the meaning “advanced” consciousness / intellect</p>
<p>[quote=“Michael, post:20, topic:417”]Yes, I do think that, as you describe, it is reasonable that a technological superpower (“parent”) could contain a planet (“sandbox”) of comparatively technologically powerless (“children”).</p>
<p>That’s similar to the power paradigm of what exists right now with conventional military superpower governments having a monopoly on force over human civilization.</p>
<p>But I think it is a leap of faith to assume it will end up that way as billions of individuals rapidly gain competitive military superpowers.[/quote]</p>
<p>What you don’t seem to grasp is the fact that with this proposed solution, a child will not understand the approach of a parent. It is like trying to grasp the idea of the internet before it was invented. Which is now being used by virtually everyone on the planet.</p>
<p>[quote=“Michael, post:20, topic:417”]All possible. But that would take a miracle to control and end human violence in the manner you’re proposing… Discovering some ~1000X unknown source of intelligence that only stays on the side of maintaining a secure healthy planet, doesn’t fall into competitive hands, and outpaces all other sources of AI development. Possible. Miracle level odds, though.</p>
<p>There is no single known reference in human history to compare such a singular uncorruptable source of planetary stabilizing power to. None.</p>
<p>All possible. But it’d be the very first time in history that such a model has ever worked, where one single entity or close cooperative group of entities can benevolently and sustainably contain the entire planet.</p>
<p>You do realize this would be the very first time EVER that your “unified parent(s) vs. children” model would exist, and that there is no known source of such 1000X intelligence beyond all other AIs yet to come, as well as no known foolproof way to contain it on the side of one benevolent competitor, right?</p>
<p>It all just seems extraordinarily speculative to assume such a miracle, first time EVER, type of format for a proposed solution.</p>
<p>Not trying to knock you personally gh0st… But that massive leap of faith for believing such a rare feat (in fact never before done in human history) will occur is why not understanding the detailed “how” part of your proposal makes this highly skeptical as a real world viable solution.[/quote]</p>
<p>Global issues are a recurring theme that has been repeating through history because of the flaws of human nature. Do you really think that the solution to HUMANITY, would be something ordinary that your primitive mind can easily conceive and grasp? (not you specifically, referring to all of us)</p>
<p>[quote=“Michael, post:20, topic:417”]Ok. Are you open to receiving and assessing strategic pitfalls to your proposed solution in order to strengthen it? Or only positive encouragement that what your saying is possible?</p>
<p>If the latter… Then, yes, what you’re saying is possible. Anything is possible, including this.[/quote]</p>
<p>Never did I only ask for positive encouragement so I don’t know why you are acting as though I am. For the sake of everyone, it would be better if I didn’t have to literally quote myself again for you, just so that you read it well enough, then maybe you can do a better job at responding with proper assessment… just some advice.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/21">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/21</link>
        <pubDate>Wed, 20 Aug 2014 03:39:25 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-21</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Michael]]></dc:creator>
        <description><![CDATA[
            <aside class="quote" data-post="19" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>This is beside my point and I was never challenging you.</p>
</blockquote>
</aside>
<p>Apologies for the misunderstanding.</p>
<aside class="quote" data-post="19" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>I was only proposing a potential solution.</p>
</blockquote>
</aside>
<p>Ok. Are you open to receiving and assessing strategic pitfalls to your proposed solution in order to strengthen it? Or only positive encouragement that what your saying is possible?</p>
<p>If the latter… Then, yes, what you’re saying is possible. Anything is possible, including this.</p>
<aside class="quote" data-post="19" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>Also likely or unlikely relative to what?</p>
</blockquote>
</aside>
<p>Likely relative to… equally matched (no 1000X disparity advantage) humans perpetuating human violence here on Earth.</p>
<p>Because without a miracle source of almighty 1000X contained intelligence coming out of left field, that’s the “default” scenario we will practically have to deal with.</p>
<aside class="quote" data-post="19" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>Was it likely that Elon musk almost single handedly built a car company that takes on a global issues, while at the same time competing with all other already established/ powerful car companies? And that it became car of the year?</p>
</blockquote>
</aside>
<p>Yes. That result was very likely compared to ending all human violence.</p>
<p>Billionaire founder who can sustain financial losses of high cost startup phase. Base technologies had already evolved to a viable degree. Corporate giant dominated industry suppressing their own electric cars (competing products) to stick to their old business models. Pent up consumer demand for new paradigm shift of business model and product. It was ripe to happen.</p>
<p>Elon Musk / Tesla Motors might be rare on a personal success level. But all within the realm of norms across the big picture of time and technical capability.</p>
<p>Tesla Motors would not have succeeded in the market had the major auto manufacturers wanted to compete based on the electric car business model earlier on.</p>
<ul>
<li>Electric Chevy Corvette</li>
<li>Electric Dodge Viper</li>
<li>Electric Economy Vehicles</li>
</ul>
<p>…back when Tesla Motors was developing its product line.</p>
<p>Tesla Motors would have probably failed under those competitive circumstances.</p>
<p>An electric car company, especially under those circumstances, is a very easy feat compared to ending human violence.</p>
<p>Apples and oranges in magnitude comparison.</p>
<aside class="quote" data-post="19" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>The logic that this approach would be effective is concluded with the example I already gave you, that of a child and an adult. Do you think that it is reasonable and logical to assume that the adult, with his higher level of intelligence / developed consciousness can solve the chaos of children in a sandbox?</p>
</blockquote>
</aside>
<p>Yes, I do think that, as you describe, it is reasonable that a technological superpower (“parent”) could contain a planet (“sandbox”) of comparatively technologically powerless (“children”).</p>
<p>That’s similar to the power paradigm of what exists right now with conventional military superpower governments having a monopoly on force over human civilization.</p>
<p>But I think it is a leap of faith to assume it will end up that way as billions of individuals rapidly gain competitive military superpowers.</p>
<p>[quote=“gh0st, post:19, topic:417”]Did you read what I said?</p>
<p>“Personally, I think if another Einstein or Nikola Tesla-like fellow (or a dedicated team of people) can’t come up with a solution to advance the human mind sufficiently or in enough time. Then we should simultaneously use our resources (print money or stop putting resources towards useless crap) to explore and get in contact with our neighbors in the universe, to try to gain knowledge / technological solutions from highly advanced ET’s”</p>
<p>If you want more “meaningful details” or a “game plan”, well I am sorry to disappoint you but I am not knowledgeable enough in the actual sciences. why don’t you try to figure it out yourself or we can try together in a productive manner.[/quote]</p>
<p>All possible. But that would take a miracle to control and end human violence in the manner you’re proposing… Discovering some ~1000X unknown source of intelligence that only stays on the side of maintaining a secure healthy planet, doesn’t fall into competitive hands, and outpaces all other sources of AI development. Possible. Miracle level odds, though.</p>
<p>There is no single known reference in human history to compare such a singular uncorruptable source of planetary stabilizing power to. None.</p>
<p>All possible. But it’d be the very first time in history that such a model has ever worked, where one single entity or close cooperative group of entities can benevolently and sustainably contain the entire planet.</p>
<p>You do realize this would be the very first time EVER that your “unified parent(s) vs. children” model would exist, and that there is no known source of such 1000X intelligence beyond all other AIs yet to come, as well as no known foolproof way to contain it on the side of one benevolent competitor, right?</p>
<p>It all just seems extraordinarily speculative to assume such a miracle, first time EVER, type of format for a proposed solution.</p>
<p>Not trying to knock you personally gh0st… But that massive leap of faith for believing such a rare feat (in fact never before done in human history) will occur is why not understanding the detailed “how” part of your proposal makes this highly skeptical as a real world viable solution.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/20">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/20</link>
        <pubDate>Wed, 20 Aug 2014 02:38:03 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-20</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[gh0st66]]></dc:creator>
        <description><![CDATA[
            <aside class="quote" data-post="18" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/letter_avatar_proxy/v2/letter/m/4bbf92/40.png" class="avatar"> Michael:</div>
<blockquote>
<p>You challenged my model with your claims that some super advanced consciousness (1000X any other competitive entity) would make these issues predictably solvable and the planet would remain sustainably healthy and happy.</p>
</blockquote>
</aside>
<aside class="quote" data-post="18" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/letter_avatar_proxy/v2/letter/m/4bbf92/40.png" class="avatar"> Michael:</div>
<blockquote>
<p>No meaningful details on even how you yourself in your own mind are able to logically conclude this is a likely outcome.</p>
</blockquote>
</aside>
<p>This is beside my point and I was never challenging you. I was only proposing a potential solution. Also likely or unlikely relative to what?  we have too little knowledge to accurately calculate likelihood. We can only calculate to a degree. Was it likely that Elon musk almost single handedly built a car company that takes on a global issues, while at the same time competing with all other already established/ powerful car companies? And that it became car of the year?</p>
<p>The logic that this approach would be effective is concluded with the example I already gave you, that of a child and an adult. Do you think that it is reasonable and logical to assume that the adult, with his higher level of intelligence / developed consciousness can solve the chaos of children in a sandbox?</p>
<aside class="quote" data-post="18" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/letter_avatar_proxy/v2/letter/m/4bbf92/40.png" class="avatar"> Michael:</div>
<blockquote>
<p>But no meaningful details are presented as to how this happens.</p>
</blockquote>
</aside>
<p>Did you read what I said?</p>
<p>“Personally, I think if another Einstein or Nikola Tesla-like fellow (or a dedicated team of people) can’t come up with a solution to advance the human mind sufficiently or in enough time. Then we should simultaneously use our resources (print money or stop putting resources towards useless crap) to explore and get in contact with our neighbors in the universe, to try to gain knowledge / technological solutions from highly advanced ET’s”</p>
<p>If you want more “meaningful details” or a “game plan”, well I am sorry to disappoint you but I am not knowledgeable enough in the actual sciences. why don’t you try to figure it out yourself or we can try together in a productive manner.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/19">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/19</link>
        <pubDate>Wed, 20 Aug 2014 00:11:32 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-19</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Michael]]></dc:creator>
        <description><![CDATA[
            <p>gh0st,</p>
<p>I’m not interested in butting heads back and forth. I’m sure you’re not either. We can nip that.</p>
<p>Here’s what occurred from my perspective…</p>
<p>I presented a thought out somewhat detailed model of sociotechnological evolution on our planet and how mass destruction is likely despite all approaches to contain it.</p>
<p>You challenged my model with your claims that some super advanced consciousness (1000X any other competitive entity) would make these issues predictably solvable and the planet would remain sustainably healthy and happy.</p>
<p>But no meaningful details are presented as to how this happens.</p>
<p>No meaningful details on even how you yourself in your own mind are able to logically conclude this is a likely outcome.</p>
<p>That’s all I was trying to understand.</p>
<p>Sorry if that was too unreasonable.</p>
<p>Thanks for your contributions. <img src="//forums.whonix.org/images/emoji/twitter/smiley.png?v=5" title=":smiley:" class="emoji" alt=":smiley:"></p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/18">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/18</link>
        <pubDate>Tue, 19 Aug 2014 23:50:52 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-18</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[gh0st66]]></dc:creator>
        <description><![CDATA[
            <p>For the sake of everyone, please stop prolonging your posts and posting multiple posts unnecessarily especially when you are essentially repeating yourself.</p>
<aside class="quote" data-post="15" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/letter_avatar_proxy/v2/letter/m/4bbf92/40.png" class="avatar"> Michael:</div>
<blockquote>
<p>We’re about to enter a world where every “child” in the sandbox has as much power, resources, and independence as the “grownups” standing by.</p>
</blockquote>
</aside>
<p>Your definition of grownups is not even reached close the scale at which I am referring to. I am talking about a thousand times more advanced human consciousness and intellect. I was talking about a child and an adult as small scale example in contrast with level of consciousness and intellect of the whole human race, relative to what you compare it to, ET’s for example of a highly advanced race. You can call it hybrid human merges with future AI if that makes you feel better, but the idea is the same. Highly advanced consiousness / intellect.</p>
<p>Just imagine how much advantage one adult has over children in a sandbox? He can do so many things that a child is unable to do or conceive. The degree of contrast is so great, these solutions would mean resources that the child could not even intellectually understand or grasp.</p>
<p>[quote=“Michael, post:15, topic:417”]But what happens when other machines or persons uses the same type of technology or AI to counter those advanced security strategies with advanced destruction strategies?</p>
<p>You can’t assume a superior difference in power between various source individuals/entities.[/quote]</p>
<p>why not…??? look at what Einstein did with nuclear power or Nikola Tesla’s achievements… (yes they were used for destructive purposes but that is only because they are still very flawed individuals with only a very marginal difference in the level of thinking relative the rest of the human race. They are still children in a sandbox compared to highly advanced consciousness/intellect such as ET’s from other planets)</p>
<aside class="quote" data-post="15" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/letter_avatar_proxy/v2/letter/m/4bbf92/40.png" class="avatar"> Michael:</div>
<blockquote>
<p>Or if you want to primarily stay on the sidelines and do positive cheerleading for those of us seriously dedicating our minds to working on these detailed problems, I would suggest not hampering those doing so, regardless if they share your optimistic, anything is possible demeanor and worldview. If they’re really working on the level of the detailed “engineering” issues of the problem, then it doesn’t help with a solution. Maybe going out to more neophyte minds and recruiting them to learn and grow and work on this stuff in greater detail is a better application of such optimism and generalized visions.</p>
</blockquote>
</aside>
<p>Trying to force me to spoon feed you a game plan for all the worlds problems, is implying that I have this highly advanced capable mind… which is obviously not true and clearly shows you are not understanding my point here.</p>
<p>Personally, I think if another Einstein or Nikola Tesla-like fellow (or a dedicated team of people) can’t come up with a solution to advance the human mind sufficiently or in enough time. Then we should simultaneously use our resources (print money or stop putting resources towards useless crap) to explore and get in contact with our neighbors in the universe, to try to gain knowledge / technological solutions from highly advanced ET’s</p>
<p>I do not doubt that dire consequences are increasing as we speak. I have been in dire consequences and have seen first hand the power of technology on a significant scale. In regard to your comment, “Or if you want to primarily stay on the sidelines and do positive cheerleading for those of us seriously dedicating our minds to working on these detailed problems”. I do my share of dedicating. I have also helped the Whonix devs a bit. What I am suggesting here is not blind hope nor is it cheer-leading optimism, it is simply using a healthy dose of optimism, reason, and logic without dwelling too much in rigid minded cynicism</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/17">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/17</link>
        <pubDate>Tue, 19 Aug 2014 17:09:08 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-17</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Michael]]></dc:creator>
        <description><![CDATA[
            <p>gh0st,</p>
<p>If you’re not talking about a regime that somehow imposes mental health upon humanity, by delivering a brain/mind/consciousness changing solution to individual humans across the planet.</p>
<p>Then… Are you trying to suggest the concept of AI as a solution to finding solutions?</p>
<p>Where either a pure computer or a hybrid human merges with future AI to then come up with solutions?</p>
<p>If that’s what you’ve been trying to suggest, then ok.</p>
<p>But what happens when other machines or persons uses the same type of technology or AI to counter those advanced security strategies with advanced destruction strategies?</p>
<p>It just turns into the equally matched waring competition scenario I spoke of.</p>
<p>But worse for the good of humanity, because to physically destroy something once is fundamentally easier than physically securing it, indefinitely, against sources of advanced persistent attack.</p>
<p>You can’t assume a superior difference in power between various source individuals/entities.</p>
<p>We do still have that now with the general power disparity of:</p>
<p>Governments  &gt;  Corporations  &gt;  Individuals</p>
<p>But, unless you somehow magically eradicate the total human population’s will or ability for violent action in the next decade or two, then your window of centralized power disparity will likely be too far gone.</p>
<p>Then it fast becomes a decentralized world of free-for-all, equally matched, individual superpowers.</p>
<p>Under those circumstances of free-for-all power, just like how internet exploitation has evolved, things honestly don’t look pretty.</p>
<p>Only fundamental difference between internet and humanity is that copies of the internet can be infinitely backed up and restored, as exploit occurs.</p>
<p>Please show me how it will likely play out otherwise, in procedural detail.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/16">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/16</link>
        <pubDate>Tue, 19 Aug 2014 09:19:20 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-16</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Michael]]></dc:creator>
        <description><![CDATA[
            <p>gh0st,</p>
<p>I do not believe I mis-understand your post. Perhaps you mis-understood mine?</p>
<p>So your rebuttle to all the detail of the problem I fleshed out was basically…</p>
<p>“If somebody comes up with a solution that works, then we will have a solution that works.”</p>
<p>And you believe that solution is likely to do with primarily focusing on the end point of the human brain/mind/consciousness.</p>
<p>Um, okay, so I agree that everything is always possible. Now what?</p>
<p>Where’s the DETAILS of this possible solution that overcome the details of the problem I fleshed out?</p>
<p>Without those details, we don’t have an actual solution.</p>
<p>We just have agreement that humanity is still searching for a solution.</p>
<p>Also, your “sandbox” “parent vs. children” worldview violates the principle of Einstein’s quote.</p>
<p>That was the 20th century and current model of virtually all major society-level activity.</p>
<p>We’re about to enter a world where every “child” in the sandbox has as much power, resources, and independence as the “grownups” standing by.</p>
<p>This 21st century sandbox is loaded with military grade weapons just sitting all around.</p>
<p>And it takes 1 uncontrollable child to unpin and drop a hand grenade inside the sandbox and blow all the parents and children to pieces.</p>
<p>Where’s the details of what your proposing?</p>
<p>How exactly do you overcome the fundamental logistics, economics, competition, and security issues I raised to install and operate your solution planet-wide across all individuals, corporations, and governments?</p>
<p>Yes. I agree that everything is possible.</p>
<p>Patrick and I started off by questioning the very nature of this reality. This could all just be a simulation, etc.</p>
<p>But, for this matter, if we accept some conventional physics and the real world objective of preserving humanity, then accomplishing such things in the world is extremely tough and rare to pull off.</p>
<p>Just try to run a small commercial company and bring a new consumer technology to market for 1 million people. If everybody was cooperative and nobody was competing against you, and R&amp;D, and materials, and manpower, and distribution, and marketing, etc were all super cheap, then it wouldn’t be that hard. Yet, it’s not easy, even for successfully building and operating something like a small company.</p>
<p>All the people you’ve referenced have failed to rid the world of violence. And that’s the minimum level of power needed to have a good shot at overcoming this.</p>
<p>Not knocking the people here. Just focused on what the problem requires to be overcome in the real world.</p>
<p>What those people have accomplished is several orders of magnitude lower than the challenge of successfully tackling the problems of massively powerful planetary destruction. Mere crumbs compared to what it will take to solve a problem more massive and powerful than anything ever faced by humanity before. A true paradigm shift.</p>
<p>Yes… anything and everything is “possible”.</p>
<p>Yes… I am happy that you personally feel creative and optimistic.</p>
<p>Yes… I am happy that you are on the side of wanting solutions.</p>
<p>But unless there is a detailed answer to overcome this near impossible problem, then we don’t have anything even remotely close yet.</p>
<p>If I’m wrong and you see the DETAILS of HOW to overcome all of this, then please don’t let me stop you from sharing those logically sound details.</p>
<p>Maybe at the end of the day our different arguments come down to this…</p>
<p>You seem focused on trying to present the issue as totally open and solvable to encourage the human spirit of yourself and others.</p>
<p>I was once at that level, but I am now past the “general” phase and am trying to understand and relay the dynamics and power of this massive problem, so that I and others can actually counter the problem and advance the detailed engineering of feasible solutions.</p>
<p>Good spirits won’t overcome this. An array of detailed technical solutions, maybe, possibly, hopefully can.</p>
<p>But one must focus their mind on the detailed power dynamics, logistical dynamics, and technical dynamics of the problem.</p>
<p>One must face the true reality of the problem if they’re serious about the details of solving it.</p>
<p>I’d invite you to really take a hard look at what it takes to get creation/invention/order/security implemented and sustained in the world and how the basic “math” is upside down in this emerging 21st century world, compared to conventional global problems.</p>
<p>I haven’t seen any detail in your arguments that take these things into account yet.</p>
<p>If you want to make real progress on figuring this out, then you’ve got to be able to resolve the detailed pitfalls on a robust, real world, planetary scale.</p>
<p>Whatever solutions you propose will be going up against the most powerful destabilizing and destructive forces known human history this century.</p>
<p>Or if you want to primarily stay on the sidelines and do positive cheerleading for those of us seriously dedicating our minds to working on these detailed problems, I would suggest not hampering those doing so, regardless if they share your optimistic, anything is possible demeanor and worldview. If they’re really working on the level of the detailed “engineering” issues of the problem, then it doesn’t help with a solution. Maybe going out to more neophyte minds and recruiting them to learn and grow and work on this stuff in greater detail is a better application of such optimism and generalized visions.</p>
<p>Personally, I invite you to on to the field, where the realities are a lot rougher and more messy, and also where solutions that look nice on the sidelines rarely work out in practice.</p>
<p>Thus is the reality of all creation/order/engineering in life.</p>
<p>Infinite ways to produce and sustain randomness/chaos/failure.</p>
<p>Quite rare to figure out how to produce and sustain truly robust creation/order/success in this world.</p>
<p>Especially when trying to engineer against the most powerful destabilizing and destructive forces known human history.</p>
<p>Maybe you could personally think of a way to better prepare minds to mentally handle the level of challenge and complexity this level of problem requires, than blunt positivity and optimism. Because those things, while they get people feeling motivated, also too often cause people not to face the realities of such hard, complex, and destructive challenges when assessing real world solutions.</p>
<p>Make no mistake. This is one of the most tough, powerful, and ugly challenges humanity has ever come up against.</p>
<p>There is a reason, other than just corruption, that the business of governments is one of the most ugly and tough businesses in the world.</p>
<p>Though, this coming paradigm shift will make governments irrelevant as entities, and dump an even bigger, nastier version of exponentially compounded human violence upon us all.</p>
<p>I’m open to detailed solutions. But not addressing the details, is just not a workable solution.</p>
<p>Encouragement/cheerleading/optimism is just that. A sideline supporting function. I don’t see it being what actually produces the real world technical solutions that can or will directly save us.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/15">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/15</link>
        <pubDate>Tue, 19 Aug 2014 07:43:29 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-15</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[gh0st66]]></dc:creator>
        <description><![CDATA[
            <p>You need to re-read my post. For example I’m not talking about “mental health regime” I am talking about advancing the human mind, improving our primitive consciousness, and intellect. I gave the example of how irrational a child is because they are not fully developed, primitive in nature, just as is the human race.</p>
<p>If one person, such as Elon Musk can tackle global issues…<br>
if one person, such as snowden can potentially tackle governments…<br>
then surely one person, who uses the science of advancing the human mind to a significant degree, can surely tackle even more global issues or come up with solutions for all of them.</p>
<p>Think of the world as a sandbox, children fighting amongst each other, imagine if an adult, someone who is more developed, more rational, more capable, and thus has more resources at his disposal to parent the children, feed them so they calm down (incentive to human nature)…etc…etc</p>
<p>This approach can be summed up by Einstein - “We can not solve our problems with the same level of thinking that created them”</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/14">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/14</link>
        <pubDate>Tue, 19 Aug 2014 05:01:57 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-14</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Michael]]></dc:creator>
        <description><![CDATA[
            <p>Attacking the problem at the source (human brain / mind / nature) is the strongest infrastructural “point of attack” (at this present stage of the world). I will give you that. No fundamental disagreement there.</p>
<p>Let’s assume that the solution you speak of, in principle looks like a combination of advanced neuroscience, psychology, biotech, nanotech, criminology/precrime, economics, social work, etc, applied across an efficient global infrastructure. Or correct me if I’m fundamentally off base.</p>
<p>Yes. Your solution could go a long way towards working, IF…</p>
<p>You get all people, corporations, and governments to openly accept it without resistance.</p>
<p>And that’s the rub.</p>
<p>End point solutions are easier to come up with.</p>
<p>How to successfully distribute and manage the solution against the free will of billions of people, millions of corporations, and thousands of governments.</p>
<p>This is where the “APPLICATION” of a strong end point solution easily breaks down and reduces its success rate.</p>
<p>Reduce your success rate down to 99%, and that means you have a pool of ~100 Million humans acting in how they do today. Say just 0.1% of those want destruction, then that’s 100,000 superpower entities pursuing destruction.</p>
<p>Every 1% reduction in global success rate of your solution equals an increase of ~100 Million of superpower entities with traditional human psychology.</p>
<p>Every 0.1% of a ~100 Million population with traditional psychology that pursues destruction equals an increase of ~100,000 mass destructive superpowers on our planet.</p>
<p>99% Success Rate = ~100 Million / ~100,000 (destructive superpowers)</p>
<p>95% Success Rate = ~500 Million / ~500,000 (destructive superpowers)</p>
<p>90% Success Rate = ~1 Billion / ~1,000,000 (destructive superpowers)</p>
<p>Your global mental health regime (whatever it consists of) could be in dire risk of being overthrown by even a handful of destructive superpowers.</p>
<p>Going up against hundreds of thousands or millions of destructive superpowers is something creative optimism doesn’t overcome without one hell of a radically paradigm shifting detailed answer of HOW such a feat is carried out and ongoingly achieved with stability throughout the indefinite 21st century and beyond.</p>
<p>This planet is already way too small for a dozen or so of conventional nuclear superpowers.</p>
<p>100s<br>
1,000s<br>
10,000s<br>
100,000s<br>
1,000,000s</p>
<p>…of futuristic superpowers actively pursuing mass destruction on this tiny home world of ours.</p>
<p>If your regime doesn’t successfully overtake the conventional already fragmented government superpowers and contain all governments, corporations, and people of the world…</p>
<p>And if your solution then doesn’t achieve and consistently sustain a virtually 100% success rate…</p>
<p>And if minority destructive forces get loose, if there is not a massively powerful security framework in place to predictably squash it…</p>
<p>Then it is game over.</p>
<p>And on top of this reality based on a human-centric model…</p>
<p>We are forgetting that mental health and psychology are irrelevant to mechanical drones and AIs.</p>
<p>Once people start programming and releasing self-sustaining drones…</p>
<p>Once people start programming and releasing artificial intelligences…</p>
<p>Also once these mechanical entities have self-replication capabilities…</p>
<p>Any regime and solution that is based on a human-centric solution starts breaking down.</p>
<p>Since now we humans are not the only superpower entities carrying out destructive programming anymore.</p>
<p>And people can multiply these independent/automated mechanical entities not just into the millions or billions with traditional manufacturing resources, but into the trillions and quadrillions and beyond with nano-manufacturing capabilities (such as nanofactories).</p>
<p>How do you contain such a force with good morals when this kind of technology becomes cheap and ubiquitous?</p>
<p>How do you uphold conventional governments for populations who individually posses as much power as said governments?</p>
<p>How do you succeed enough across the entire planet in cutting off the evolution of such technology while we’re still contained in the conventional human-centric paradigm right now?</p>
<p>Look at how the internet is overrun with viruses/malware/hacking. Figure out how to squash all of that and secure everyone’s computers in the real world where everyone has free will with their devices and that would be a good trial run for the coming model of free-for-all competition amongst billions of equally matched superpower entities.</p>
<p>I’m not trying to squash optimism or creativity just because it somehow feels good to me.</p>
<p>We both want the same/similar outcome for humanity, I’m sure.</p>
<p>I’m not trying to brush off the type of solution you’re proposing. I’ve considered the type of stuff your talking about for years now.</p>
<p>My argument is independent of that.</p>
<p>If one doesn’t ignore the simple realities I’ve presented, the basic “math” is COMPLETELY UPSIDE DOWN for successfully containing this, no matter what type of approach you use.</p>
<p>You have to present a specific solution/algorithm that can overcome the virtually impossible task of human influence and tight security containment on a planetary scale.</p>
<p>Without a specific solution, all one has is their personal feelings of optimism and creativity.</p>
<p>I’m sure there were people who felt the same sense of optimism and creativity working on anti-virus and software security solutions back in the mid 1990s who thought the internet would soon be safe and healthy and happy.</p>
<p>Reality proved them wrong. For many reasons.</p>
<p>I’m all for those feelings on a personal level. Anything to increase people’s state of health and happiness is generally a good thing.</p>
<p>But we’re dealing with issues of mass survival and extinction here.</p>
<p>No backup copies exist for humanity.</p>
<p>It’s a really serious thing.</p>
<p>Not that you don’t take it seriously. Just framing my own perspective on this.</p>
<p>Anyway, like I said, I’m open to hearing detailed solutions that really take into account the fundamentally hard problems I presented of successfully applying a solution.</p>
<p>Theoretical end point solutions that don’t also account for “HOW” they get predictably adopted and distributed across all people, corporations, and governments and then can be robustly maintained at extraordinarily high success rates, ultimately do not answer the challenge.</p>
<p>A real (non band-aid) answer for humanity needs to pass these basic thresholds.</p>
<p>It takes a complex multi-polar, massive scale, massive complexity, new 21st century way of thinking to wrap one’s head around the full scale of the problem.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/13">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/13</link>
        <pubDate>Tue, 19 Aug 2014 03:40:35 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-13</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[gh0st66]]></dc:creator>
        <description><![CDATA[
            <p>[quote=“Michael, post:11, topic:417”]I sympathize with your optimistic sentiments and the notion of at least “trying”.</p>
<p>But even everything you propose still just amounts to a band-aid, compared to the power and scale which the problem possesses.</p>
<p>Anything is possible. Just not likely probable to work, though.</p>
<p>I described this in long format. I’ll summarize in short principle format:</p>
<ul>
<li>
<p>Maintaining creation/order/security of something against an APT (advanced persistent threat) generally requires successful prevention at every single instance of every single day, hour, minute, etc. ~100% success rate required.</p>
</li>
<li>
<p>APT destruction generally requires 1 successful attempt to penetrate defenses and destroy something. No backup copies for human beings. Below 1% success rate required.</p>
</li>
<li>
<p>There is too many humans to monitor/influence/control, too much physical open space, too much technological freedom and capability, too much behavioral entropy/randomness/unpredictability, when it comes to billions of people who individually possess global destruction capabilities.</p>
</li>
</ul>
<p>I’m not saying that humanity, in a multitude of ways, can’t or shouldn’t fight back to stop such global destruction and maybe succeed 70, 80, 90 some percent of the time. The fundamental problem though is that it only takes a fraction of 1% success rate for global destruction to “win” in a world of such technologically advanced decentralized power.</p>
<p>The “math” of the scale and odds just don’t work out in the favor of maintaining creation/order/security. Even if you assume amazing futuristic security and mental health capabilities.[/quote]</p>
<p>I don’t blame you or anyone else for having a cynical view, given the current circumstances. But I think this may only hinder creativity if one dwells too much.</p>
<p>Maintaining creation/order/security being required every minute with 100% success rate is an appealing solution if one is focused on the forest for the trees. As I said if resources are used to study, understand, and remedy the human mind itself and deploy it properly then the possibilities can render this flawed band-aid of a solution even more useless.</p>
<p>Just think of a child, who needs almost 24/7 care because their brains are not fully developed, they don’t know how to properly navigate their intelligence. They whine, cry, fight with little rationality. They are primitive in nature and sensitive to everything around them. Similarly, the human race is primitive in this current stage. The only difference between a baby and an adult is that adults only have a marginal increase in rationality yet much greater consequences,</p>
<p>Just as it only takes one person to potentially destroy the world. It only takes one person to save it. Likelihood is almost irrelevant. Just think about the creation of the internet. One person developed technology that is now developed into something which is in the hands of almost everyone on the planet. How do you think that happened? Because it was an incentive to human nature. Just think about the fact that all governments are doing very similar technological approaches for similar purposes of controlling citizens for power and defense. Also, with the Snowden leaks, even more governments will begin implementing these tactics in their arsenal. Why are they doing that? Because it is also an incentive to human nature. Just imagine what can be done to save the planet, by creating an incentive of some form, for the people, or for government to endorse and implement for their country. As you said so yourself “governments as entities are the most absolute strongest sources of authority and power that exist in conventional society.”</p>
<p>Maybe the incentive itself can be some form of remedy to advance the human mind that will ultimately serve the greater good. Currently, there is not even a small fraction of resources being used to study and advance this subject in comparison to all these band-aid solutions everyone loves to propose. Just imagine the possibilities if we put half of those resources into studying and advancing the human consciousness</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/12">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/12</link>
        <pubDate>Sun, 17 Aug 2014 17:53:02 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-12</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[Michael]]></dc:creator>
        <description><![CDATA[
            <aside class="quote" data-post="10" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>decentralized power doesn’t have to automatically = decentralized evil power.</p>
</blockquote>
</aside>
<p>Agreed. Power = Power. And in any situation there is always multiple sources of power with differing motivations, either neutral, conflicting, or cooperative to each other.</p>
<aside class="quote" data-post="10" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>The source of all the major problems is obviously human nature</p>
</blockquote>
</aside>
<p>Agreed. That is our base programming which directs our tangible actions and sense of meaning that people give things.</p>
<p>I’ve personally spent several years studying human psychology, and love the subject.</p>
<aside class="quote" data-post="10" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>If we change our focus and use some of the trillions of dollars and resources towards understanding and remedying the human mind, I believe we can have better chance than anything ever could at saving ourselves, building proper infrastructure, and promising global systems to learn, discover, detect, and deploy major problems before they can come close to arising. The evil in humans is almost as much of a sickness as any other mental illness. This approach is better than trying to band-aid everything, only for it to replicate into more problems again in the future.</p>
</blockquote>
</aside>
<p>I sympathize with your optimistic sentiments and the notion of at least “trying”.</p>
<p>But even everything you propose still just amounts to a band-aid, compared to the power and scale which the problem possesses.</p>
<p>Anything is possible. Just not likely probable to work, though.</p>
<p>I described this in long format. I’ll summarize in short principle format:</p>
<ul>
<li>
<p>Maintaining creation/order/security of something against an APT (advanced persistent threat) generally requires successful prevention at every single instance of every single day, hour, minute, etc. ~100% success rate required.</p>
</li>
<li>
<p>APT destruction generally requires 1 successful attempt to penetrate defenses and destroy something. No backup copies for human beings. Below 1% success rate required.</p>
</li>
<li>
<p>There is too many humans to monitor/influence/control, too much physical open space, too much technological freedom and capability, too much behavioral entropy/randomness/unpredictability, when it comes to billions of people who individually possess global destruction capabilities.</p>
</li>
</ul>
<p>I’m not saying that humanity, in a multitude of ways, can’t or shouldn’t fight back to stop such global destruction and maybe succeed 70, 80, 90 some percent of the time. The fundamental problem though is that it only takes a fraction of 1% success rate for global destruction to “win” in a world of such technologically advanced decentralized power.</p>
<p>The “math” of the scale and odds just don’t work out in the favor of maintaining creation/order/security. Even if you assume amazing futuristic security and mental health capabilities.</p>
<aside class="quote" data-post="10" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
 gh0st:</div>
<blockquote>
<p>If Snowden, with all his coverage and exposure, not only leaked issues, but proposed and encouraged more solutions for not only the people, but for the governments themselves. It would do a much greater good for everyone, including potentially preventing his own peril</p>
</blockquote>
</aside>
<p>That’s a nice sentiment. And yes, everyone, can do “more good”.</p>
<p>The question is… Will our best even come close to being enough?</p>
<p>Even Snowden’s best that you imagine would not have removed mass surveillance functions from governments.</p>
<p>The reason we have mass surveillance has much more to do with the low costs and high capabilities of modern computing technology, as well as the military-industrial complex having high levels of power throughout governments and societies around the globe, plus the sheep-like complacency of everyday people to simply not care to invest much in their personal privacy and security.</p>
<p>Even more and more local governments are now working to gain more and more NSA like spying/surveillance capabilities.</p>
<p>Also governments as entities are the most absolute strongest sources of authority and power that exist in conventional society. So governments, especially executive, police, and military branches, are known to psychologically draw corrupt power hungry sociopathic people out of society to these positions like insects to sweet honey.</p>
<p>If Edward Snowden or anybody else could spend a full day, one on one, with every single person on the planet and teach them all about why and how they should protect themselves and demand change from governments, it would “help some” and do “more good”, but at the end of the day, we would still have powerful military-industrial complexes leveraging mass surveillance against most of the human population.</p>
<p>Because, most people just don’t care to put in much effort for these things in life. Trust me, I’ve tried to educate and encourage most of my family and friends. They ultimately don’t care and just want to be typical consumers of modern mainstream society. And mass corporations dominate most of products people buy and marketing they see, and can offer lower prices, etc. And national governments are MUCH BIGGER GIANTS in size (manpower and money) and power (police/military/weapons) compared to business corporations and they require/coerce businesses to participate and support their surveillance goals.</p>
<p>Edward Snowden could not have realistically changed this global paradigm. He can only realistically make small dings in it.</p>
<p>Sure, anything is “possible”. Butterfly effects and such. But the winds of entropy blow both directions and often cancel each other out over time.</p>
<p>All that said, I’m not saying we should just let things happen unchecked.</p>
<p>I believe in putting up a fight against evil, tyranny, and destruction.</p>
<p>The alternative of putting up no defenses is worse.</p>
<p>I just think it is naive and less effective to not have a true understanding of the true scale and power of the beast one is going up against.</p>
<p>Some people emotionally need a sense of optimism to muster the will to go on fighting. Personally, I used to need to operate this way myself with challenges earlier in my life (requiring optimistic views). Yet optimism, like pessimism, often encourages turning a blind eye to the realistic odds and mechanisms that influence how things will most likely play out.</p>
<p>If you see a detailed way to overcome all of the major forces and mechanisms I’ve described to predictably stop such destruction, then I would be interested in reading an explanation of how that would actually play out and robustly ensure that billions of humans can’t be killed via using advanced automated technology.</p>
<p>I’ve been racking my brain for years on the implications of this coming decentralized power shift, and while I see many ways to try and contain it, I can’t see how to ensure the near ~100% success rate it would take across the entire planet.</p>
<p>But I’m open to seeing a differing detailed perspective of “how” to do so that overcomes such a powerful threat.</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/11">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/11</link>
        <pubDate>Sun, 17 Aug 2014 05:54:32 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-11</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
      <item>
        <title>Open letter to Edward Snowden</title>
        <dc:creator><![CDATA[gh0st66]]></dc:creator>
        <description><![CDATA[
            <p>[quote=“Michael, post:9, topic:417”]Attempting to enslave billions via Luddite martial law, or only focusing on detectably mentally ill people will not work because it leaves way too much opportunity for individuals to acquire technology and “go rogue”.</p>
<p>Not trying to be a pessimist, or an optimist, here. Just trying to play out the real scales, odds, motives, and capabilities of the human race against this newly emerging paradigm of decentralized power. I don’t see a practical way to stop or contain it, before it is here. Once it is here, then it is just a free-for-all of waring competition from all directions.[/quote]</p>
<p>decentralized power doesn’t have to automatically = decentralized evil power. Which by the way, already exists. But it is true that as technology advances, decentralized evil power will have much greater dire consequences… Though with the combination of decentralized technology for the greater good and remedying fundamental flaws of human nature could stand a chance</p>
<p>The source of all the major problems is obviously human nature, but to put it in a more optimistic way, it is our primitive understanding of human nature (thus, the inability to remedy it). Technology just provides a magnification of human nature, which is evidently reflected in these global issues. Humans are a magnificent creation. We have powerful minds that are actually amazing problem solving machines. If we change our focus and use some of the trillions of dollars and resources towards understanding and remedying the human mind, I believe we can have better chance than anything ever could at saving ourselves, building proper infrastructure, and promising global systems to learn, discover, detect, and deploy major problems before they can come close to arising. The evil in humans is almost as much of a sickness as any other mental illness. This approach is better than trying to band-aid everything, only for it to replicate into more problems again in the future.</p>
<p>[quote=“Michael, post:9, topic:417”]Realistically, I see no saving force that will stop or meaningfully slow this inevitability.</p>
<p>And I’m certainly not counting on goodness or love or other positives of human nature to override the bad parts of human nature across 100% of humanity.[/quote]</p>
<p>I don’t intend to get all preachy here, only to shed light on the optimistic side of it all, just as it only takes one person to potentially cause mass destruction. It also only takes one person to potentially crush governments or tackle global issues… take Snowden or Elon Musk for example.</p>
<aside class="quote" data-post="9" data-topic="417">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/letter_avatar_proxy/v2/letter/m/4bbf92/40.png" class="avatar"> Michael:</div>
<blockquote>
<p>But based on where things are this moment today, in 2014, upholding moral principles as Edward Snowden has done is a shining example of the good that makes humanity worth preserving and celebrating, even if our collective civilization falls in the process. <img src="//forums.whonix.org/images/emoji/twitter/slight_smile.png?v=5" title=":slight_smile:" class="emoji" alt=":slight_smile:"></p>
</blockquote>
</aside>
<p>I don’t think it has to “fall in the process”. If Snowden, with all his coverage and exposure, not only leaked issues, but proposed and encouraged more solutions for not only the people, but for the governments themselves. It would do a much greater good for everyone, including potentially preventing his own peril</p>
          <p><a href="http://forums.whonix.org/t/open-letter-to-edward-snowden/417/10">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/open-letter-to-edward-snowden/417/10</link>
        <pubDate>Sat, 16 Aug 2014 19:25:22 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-417-10</guid>
        <source url="http://forums.whonix.org/t/open-letter-to-edward-snowden/417.rss">Open letter to Edward Snowden</source>
      </item>
  </channel>
</rss>
