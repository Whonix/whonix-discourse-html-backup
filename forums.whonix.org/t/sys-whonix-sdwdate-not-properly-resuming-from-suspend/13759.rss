<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
    <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759</link>
    <description>Hello there,

Qubes 4.1.
sdwdate: 3:19.7-1

With all updates installed under whonix-gw-16, when the system wakes up from suspend, sys-whonix keeps a whole core at 100% CPU usage and Terminal opened prior of going into suspend are unresponsive. sdwdate-gui tor-control-panel can be opened, but trying to Restart Tor or any action happening there will freeze that window as well.

If I keep open a terminal to have top running, it doesn&#39;t update anymore and timestamp is stuck to the time system suspended. 

If I launch `qvm-run --no-gui --pass-io sys-whonix &quot;ps fauxwwww&quot;` I see that sdwdate&#39;s invocation of `tor-circuit-established-check` is consuming more and more memory (90%) and then swapping is occuring, even though its parent is launching it through `timeout --kill-after=5s`, which never occurs. xen-balloning and `systemd --user` are also eating a lot of CPU. Traffic is not routed through tor.

Note that qvm-run calls are not always successful either, and `sudo killall sdwdate` or `sudo systemctl stop sdwdate` doesn&#39;t reestablish windows availability, even though the processes disappeared.



Any debugging insights here?


Reinstalling whonix-gw-16 through `qvm-template reinstall whonix-gw-16` doesn&#39;t show behavior, which is deploying sdwdate: 3:19.1-1. Upgrading whonix-gw-16 to latest exhibits those behaviors again.  Not sure the problem is directly linked to sdwdate.

Cloned whonix-gw-16 to whonix-gw-16_latest. Now trying to downgrade some packages to isolate the problem source.</description>
    <language>en</language>
    <lastBuildDate>Sat, 11 Jun 2022 14:56:18 +0000</lastBuildDate>
    <category>Qubes-Whonix</category>
    <atom:link href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss" rel="self" type="application/rss+xml" />
      <item>
        <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
        <dc:creator><![CDATA[Patrick]]></dc:creator>
        <description><![CDATA[
            <p>Also discussed here:</p>
<aside class="onebox allowlistedgeneric" data-onebox-src="https://forum.qubes-os.org/t/suspend-swap-and-whonix-gateway-performance-issues/11310">
  <header class="source">
      <img src="https://forum.qubes-os.org/uploads/db3820/optimized/2X/5/55de5eaf64516902429c411f66491cc9db06c464_2_32x32.png" class="site-icon" width="32" height="32">

      <a href="https://forum.qubes-os.org/t/suspend-swap-and-whonix-gateway-performance-issues/11310" target="_blank" rel="noopener" title="10:37PM - 07 May 2022">Qubes OS Forum ‚Äì 7 May 22</a>
  </header>

  <article class="onebox-body">
    <div class="aspect-image" style="--aspect-ratio:472/471;"><img src="https://forum.qubes-os.org/uploads/db3820/original/1X/10549f9dff8a289d117f083e9f5155231c452db2.png" class="thumbnail" width="472" height="471"></div>

<h3><a href="https://forum.qubes-os.org/t/suspend-swap-and-whonix-gateway-performance-issues/11310" target="_blank" rel="noopener">Suspend, swap, and whonix-gateway performance issues</a></h3>

  <p>Hi,  since about a week ago, my whonix gateways start swapping heavily after resuming from suspend. Does anyone have similar issues, and maybe good ways to investigate this?  Thank you!</p>

  <p>
    <span class="label1">Reading time: 2 mins üïë</span>
      <span class="label2">Likes: 8 ‚ù§</span>
  </p>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both"></div>
</aside>

          <p><a href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/11">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/11</link>
        <pubDate>Sat, 11 Jun 2022 14:56:18 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-13759-11</guid>
        <source url="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss">sys-whonix (sdwdate) not properly resuming from suspend</source>
      </item>
      <item>
        <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
        <dc:creator><![CDATA[tlaurion]]></dc:creator>
        <description><![CDATA[
            <aside class="onebox githubpullrequest" data-onebox-src="https://github.com/QubesOS/qubes-core-admin/pull/473">
  <header class="source">

      <a href="https://github.com/QubesOS/qubes-core-admin/pull/473" target="_blank" rel="noopener nofollow ugc">github.com/QubesOS/qubes-core-admin</a>
  </header>

  <article class="onebox-body">
    <div class="github-row">
  <div class="github-icon-container" title="Pull Request">
    <svg width="60" height="60" class="github-icon" viewBox="0 0 12 16" aria-hidden="true"><path d="M11 11.28V5c-.03-.78-.34-1.47-.94-2.06C9.46 2.35 8.78 2.03 8 2H7V0L4 3l3 3V4h1c.27.02.48.11.69.31.21.2.3.42.31.69v6.28A1.993 1.993 0 0 0 10 15a1.993 1.993 0 0 0 1-3.72zm-1 2.92c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zM4 3c0-1.11-.89-2-2-2a1.993 1.993 0 0 0-1 3.72v6.56A1.993 1.993 0 0 0 2 15a1.993 1.993 0 0 0 1-3.72V4.72c.59-.34 1-.98 1-1.72zm-.8 10c0 .66-.55 1.2-1.2 1.2-.65 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"></path></svg>
  </div>

  <div class="github-info-container">
    <h4>
      <a href="https://github.com/QubesOS/qubes-core-admin/pull/473" target="_blank" rel="noopener nofollow ugc">Properly suspend all VMs, not only those with PCI devices</a>
    </h4>

    <div class="branches">
      <code>QubesOS:master</code> ‚Üê <code>marmarek:suspend-all</code>
    </div>

    <div class="github-info">
      <div class="date">
        opened <span class="discourse-local-date" data-format="ll" data-date="2022-05-03" data-time="15:06:49" data-timezone="UTC">03:06PM - 03 May 22 UTC</span>
      </div>

      <div class="user">
        <a href="https://github.com/marmarek" target="_blank" rel="noopener nofollow ugc">
          <img alt="marmarek" src="https://avatars.githubusercontent.com/u/726704?v=4" class="onebox-avatar-inline" width="20" height="20">
          marmarek
        </a>
      </div>

      <div class="lines" title="1 commits changed 1 files with 5 additions and 8 deletions">
        <a href="https://github.com/QubesOS/qubes-core-admin/pull/473/files" target="_blank" rel="noopener nofollow ugc">
          <span class="added">+5</span>
          <span class="removed">-8</span>
        </a>
      </div>
    </div>
  </div>
</div>

  <div class="github-row">
    <p class="github-body-container">Just pausing a VM for a host suspend breaks 'tsc' clocksource.

QubesOS/qubes-<span class="show-more-container"><a href="https://github.com/QubesOS/qubes-core-admin/pull/473" target="_blank" rel="noopener nofollow ugc" class="show-more">‚Ä¶</a></span><span class="excerpt hidden">issues#7404
QubesOS/qubes-issues#2044

TODO:

- [ ] test with mirage PVH
- [ ] suspend (instead of pause) stubdomain too
- [ ] Fix QWT to not remove xenstore entry (https://github.com/QubesOS/qubes-issues/issues/7404#issuecomment-1117611495)</span></p>
  </div>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both"></div>
</aside>

<p>might also be part of the long term solution</p>
          <p><a href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/10">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/10</link>
        <pubDate>Fri, 10 Jun 2022 22:15:19 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-13759-10</guid>
        <source url="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss">sys-whonix (sdwdate) not properly resuming from suspend</source>
      </item>
      <item>
        <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
        <dc:creator><![CDATA[tlaurion]]></dc:creator>
        <description><![CDATA[
            <p>I confirm that</p>
<aside class="onebox githubissue" data-onebox-src="https://github.com/QubesOS/updates-status/issues/2970">
  <header class="source">

      <a href="https://github.com/QubesOS/updates-status/issues/2970" target="_blank" rel="noopener nofollow ugc">github.com/QubesOS/updates-status</a>
  </header>

  <article class="onebox-body">
    <div class="github-row">
  <div class="github-icon-container" title="Issue">
	  <svg width="60" height="60" class="github-icon" viewBox="0 0 14 16" aria-hidden="true"><path d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg>
  </div>

  <div class="github-info-container">
    <h4>
      <a href="https://github.com/QubesOS/updates-status/issues/2970" target="_blank" rel="noopener nofollow ugc">linux-kernel v5.10.121-1 (r4.1)</a>
    </h4>

    <div class="github-info">
      <div class="date">
        opened <span class="discourse-local-date" data-format="ll" data-date="2022-06-10" data-time="21:21:03" data-timezone="UTC">09:21PM - 10 Jun 22 UTC</span>
      </div>


      <div class="user">
        <a href="https://github.com/qubesos-bot" target="_blank" rel="noopener nofollow ugc">
          <img alt="qubesos-bot" src="https://avatars.githubusercontent.com/u/24401983?v=4" class="onebox-avatar-inline" width="20" height="20">
          qubesos-bot
        </a>
      </div>
    </div>

    <div class="labels">
        <span style="display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;">
          r4.1-dom0-cur-test
        </span>
    </div>
  </div>
</div>

  <div class="github-row">
    <p class="github-body-container">Update of linux-kernel to v5.10.121-1 for Qubes r4.1, see comments below for det<span class="show-more-container"><a href="http://forums.whonix.org" rel="noopener" class="show-more">‚Ä¶</a></span><span class="excerpt hidden">ails.

Built from: https://github.com/QubesOS/qubes-linux-kernel/commit/c5104766963d4bdbaa9ec329a521a51bc41be289

[Changes since previous version](https://github.com/QubesOS/qubes-linux-kernel/compare/v5.10.112-1...v5.10.121-1):
QubesOS/qubes-linux-kernel@c510476 version 5.10.121-1
QubesOS/qubes-linux-kernel@a18f839 Merge remote-tracking branch 'origin/pr/594' into stable-5.10
QubesOS/qubes-linux-kernel@3a84c17 Revert "Switch default clocksource to 'tsc'"
QubesOS/qubes-linux-kernel@ac59b28 Update to kernel-5.10.119
QubesOS/qubes-linux-kernel@10df8ee ci: use default tags

Referenced issues:
QubesOS/qubes-issues#7404

If you're release manager, you can issue GPG-inline signed command:

* `Upload linux-kernel c5104766963d4bdbaa9ec329a521a51bc41be289 r4.1 current repo` (available 7 days from now)
* `Upload linux-kernel c5104766963d4bdbaa9ec329a521a51bc41be289 r4.1 current (dists) repo`, you can choose subset of distributions, like `vm-fc24 vm-fc25` (available 7 days from now)
* `Upload linux-kernel c5104766963d4bdbaa9ec329a521a51bc41be289 r4.1 security-testing repo`

Above commands will work only if packages in current-testing repository were built from given commit (i.e. no new version superseded it).</span></p>
  </div>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both"></div>
</aside>

<p>fixes the issue.</p>
          <p><a href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/9">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/9</link>
        <pubDate>Fri, 10 Jun 2022 22:11:07 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-13759-9</guid>
        <source url="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss">sys-whonix (sdwdate) not properly resuming from suspend</source>
      </item>
      <item>
        <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
        <dc:creator><![CDATA[tlaurion]]></dc:creator>
        <description><![CDATA[
            <p>Related qubes issue:</p>
<aside class="onebox githubissue" data-onebox-src="https://github.com/QubesOS/updates-status/issues/2970">
  <header class="source">

      <a href="https://github.com/QubesOS/updates-status/issues/2970" target="_blank" rel="noopener nofollow ugc">github.com/QubesOS/updates-status</a>
  </header>

  <article class="onebox-body">
    <div class="github-row">
  <div class="github-icon-container" title="Issue">
	  <svg width="60" height="60" class="github-icon" viewBox="0 0 14 16" aria-hidden="true"><path d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg>
  </div>

  <div class="github-info-container">
    <h4>
      <a href="https://github.com/QubesOS/updates-status/issues/2970" target="_blank" rel="noopener nofollow ugc">linux-kernel v5.10.121-1 (r4.1)</a>
    </h4>

    <div class="github-info">
      <div class="date">
        opened <span class="discourse-local-date" data-format="ll" data-date="2022-06-10" data-time="21:21:03" data-timezone="UTC">09:21PM - 10 Jun 22 UTC</span>
      </div>


      <div class="user">
        <a href="https://github.com/qubesos-bot" target="_blank" rel="noopener nofollow ugc">
          <img alt="qubesos-bot" src="https://avatars.githubusercontent.com/u/24401983?v=4" class="onebox-avatar-inline" width="20" height="20">
          qubesos-bot
        </a>
      </div>
    </div>

    <div class="labels">
        <span style="display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;">
          r4.1-dom0-cur-test
        </span>
    </div>
  </div>
</div>

  <div class="github-row">
    <p class="github-body-container">Update of linux-kernel to v5.10.121-1 for Qubes r4.1, see comments below for det<span class="show-more-container"><a href="http://forums.whonix.org" rel="noopener" class="show-more">‚Ä¶</a></span><span class="excerpt hidden">ails.

Built from: https://github.com/QubesOS/qubes-linux-kernel/commit/c5104766963d4bdbaa9ec329a521a51bc41be289

[Changes since previous version](https://github.com/QubesOS/qubes-linux-kernel/compare/v5.10.112-1...v5.10.121-1):
QubesOS/qubes-linux-kernel@c510476 version 5.10.121-1
QubesOS/qubes-linux-kernel@a18f839 Merge remote-tracking branch 'origin/pr/594' into stable-5.10
QubesOS/qubes-linux-kernel@3a84c17 Revert "Switch default clocksource to 'tsc'"
QubesOS/qubes-linux-kernel@ac59b28 Update to kernel-5.10.119
QubesOS/qubes-linux-kernel@10df8ee ci: use default tags

Referenced issues:
QubesOS/qubes-issues#7404

If you're release manager, you can issue GPG-inline signed command:

* `Upload linux-kernel c5104766963d4bdbaa9ec329a521a51bc41be289 r4.1 current repo` (available 7 days from now)
* `Upload linux-kernel c5104766963d4bdbaa9ec329a521a51bc41be289 r4.1 current (dists) repo`, you can choose subset of distributions, like `vm-fc24 vm-fc25` (available 7 days from now)
* `Upload linux-kernel c5104766963d4bdbaa9ec329a521a51bc41be289 r4.1 security-testing repo`

Above commands will work only if packages in current-testing repository were built from given commit (i.e. no new version superseded it).</span></p>
  </div>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both"></div>
</aside>

          <p><a href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/8">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/8</link>
        <pubDate>Fri, 10 Jun 2022 21:42:44 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-13759-8</guid>
        <source url="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss">sys-whonix (sdwdate) not properly resuming from suspend</source>
      </item>
      <item>
        <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
        <dc:creator><![CDATA[tlaurion]]></dc:creator>
        <description><![CDATA[
            <p>Still not sure I understand why the behavior shows only in latest version of whonix-gw-16 and not in original template deployed packages. So there seems to be something else that impacts this linked to packages of whonix-gw-16 itself and the kernel exposed by dom0 used by sys-whonix.</p>
<p>diff between packages deployed on template vs latest:</p>
<pre><code class="lang-auto">4,10c4,9
&lt; anon-apps-config/now 3:6.2-1 all [installed,upgradable to: 3:6.4-1]
&lt; anon-apt-sources-list/now 3:5.0-1 all [installed,upgradable to: 3:5.2-1]
&lt; anon-connection-wizard/now 1:6.2-1 all [installed,upgradable to: 1:6.6-1]
&lt; anon-gw-anonymizer-config/now 3:12.6-1 all [installed,upgradable to: 3:13.4-1]
&lt; anon-gw-base-files/now 3:4.0-1 all [installed,upgradable to: 3:4.1-1]
&lt; anon-icon-pack/now 3:3.3-1 all [installed,local]
&lt; apparmor-profile-dist/now 3:7.7-1 all [installed,upgradable to: 3:7.8-1]
---
&gt; anon-apps-config/unknown,now 3:6.4-1 all [installed,automatic]
&gt; anon-apt-sources-list/unknown,now 3:5.2-1 all [installed,automatic]
&gt; anon-connection-wizard/unknown,now 1:6.6-1 all [installed,automatic]
&gt; anon-gw-anonymizer-config/unknown,now 3:13.4-1 all [installed,automatic]
&gt; anon-gw-base-files/unknown,now 3:4.1-1 all [installed,automatic]
&gt; apparmor-profile-dist/unknown,now 3:7.8-1 all [installed,automatic]
19c18
&lt; base-files/now 11.1+deb11u2 amd64 [installed,upgradable to: 11.1+deb11u3]
---
&gt; base-files/stable,now 11.1+deb11u3 amd64 [installed]
25,28c24,27
&lt; bind9-dnsutils/now 1:9.16.22-1~deb11u1 amd64 [installed,upgradable to: 1:9.16.27-1~deb11u1]
&lt; bind9-host/now 1:9.16.22-1~deb11u1 amd64 [installed,upgradable to: 1:9.16.27-1~deb11u1]
&lt; bind9-libs/now 1:9.16.22-1~deb11u1 amd64 [installed,upgradable to: 1:9.16.27-1~deb11u1]
&lt; bindp/now 3:2.6-1 all [installed,upgradable to: 3:2.7-1]
---
&gt; bind9-dnsutils/stable,stable-security,now 1:9.16.27-1~deb11u1 amd64 [installed,automatic]
&gt; bind9-host/stable,stable-security,now 1:9.16.27-1~deb11u1 amd64 [installed,automatic]
&gt; bind9-libs/stable,stable-security,now 1:9.16.27-1~deb11u1 amd64 [installed,automatic]
&gt; bindp/unknown,now 3:2.7-1 all [installed,automatic]
32,34c31,33
&lt; bootclockrandomization/now 3:5.2-1 all [installed,upgradable to: 3:5.3-1]
&lt; bsdextrautils/now 2.36.1-8 amd64 [installed,upgradable to: 2.36.1-8+deb11u1]
&lt; bsdutils/now 1:2.36.1-8 amd64 [installed,upgradable to: 1:2.36.1-8+deb11u1]
---
&gt; bootclockrandomization/unknown,now 3:5.3-1 all [installed,automatic]
&gt; bsdextrautils/stable,stable-security,now 2.36.1-8+deb11u1 amd64 [installed,automatic]
&gt; bsdutils/stable,stable-security,now 1:2.36.1-8+deb11u1 amd64 [installed]
46c45
&lt; damngpl/now 3:3.2-1 all [installed,upgradable to: 3:3.3-1]
---
&gt; damngpl/unknown,now 3:3.3-1 all [installed,automatic]
63,64c62,63
&lt; dirmngr/now 2.2.27-2 amd64 [installed,upgradable to: 2.2.27-2+deb11u1]
&lt; dist-base-files/now 3:8.1-1 all [installed,upgradable to: 3:8.2-1]
---
&gt; dirmngr/stable,now 2.2.27-2+deb11u1 amd64 [installed,automatic]
&gt; dist-base-files/unknown,now 3:8.2-1 all [installed,automatic]
70,72c69,71
&lt; dnsutils/now 1:9.16.22-1~deb11u1 all [installed,upgradable to: 1:9.16.27-1~deb11u1]
&lt; dpkg-dev/stable,now 1.20.9 all [installed,upgradable to: 1.20.10]
&lt; dpkg/stable,now 1.20.9 amd64 [installed,upgradable to: 1.20.10]
---
&gt; dnsutils/stable,stable-security,now 1:9.16.27-1~deb11u1 all [installed,automatic]
&gt; dpkg-dev/stable-security,now 1.20.10 all [installed,automatic]
&gt; dpkg/stable-security,now 1.20.10 amd64 [installed]
81c80
&lt; fdisk/now 2.36.1-8 amd64 [installed,upgradable to: 2.36.1-8+deb11u1]
---
&gt; fdisk/stable,stable-security,now 2.36.1-8+deb11u1 amd64 [installed]
100c99
&lt; gir1.2-gtk-3.0/now 3.24.24-4 amd64 [installed,upgradable to: 3.24.24-4+deb11u2]
---
&gt; gir1.2-gtk-3.0/stable,now 3.24.24-4+deb11u2 amd64 [installed,automatic]
107,109c106,108
&lt; gnupg-l10n/now 2.2.27-2 all [installed,upgradable to: 2.2.27-2+deb11u1]
&lt; gnupg-utils/now 2.2.27-2 amd64 [installed,upgradable to: 2.2.27-2+deb11u1]
&lt; gnupg/now 2.2.27-2 all [installed,upgradable to: 2.2.27-2+deb11u1]
---
&gt; gnupg-l10n/stable,now 2.2.27-2+deb11u1 all [installed,automatic]
&gt; gnupg-utils/stable,now 2.2.27-2+deb11u1 amd64 [installed,automatic]
&gt; gnupg/stable,now 2.2.27-2+deb11u1 all [installed]
113,119c112,118
&lt; gpg-agent/now 2.2.27-2 amd64 [installed,upgradable to: 2.2.27-2+deb11u1]
&lt; gpg-wks-client/now 2.2.27-2 amd64 [installed,upgradable to: 2.2.27-2+deb11u1]
&lt; gpg-wks-server/now 2.2.27-2 amd64 [installed,upgradable to: 2.2.27-2+deb11u1]
&lt; gpg/now 2.2.27-2 amd64 [installed,upgradable to: 2.2.27-2+deb11u1]
&lt; gpgconf/now 2.2.27-2 amd64 [installed,upgradable to: 2.2.27-2+deb11u1]
&lt; gpgsm/now 2.2.27-2 amd64 [installed,upgradable to: 2.2.27-2+deb11u1]
&lt; gpgv/now 2.2.27-2 amd64 [installed,upgradable to: 2.2.27-2+deb11u1]
---
&gt; gpg-agent/stable,now 2.2.27-2+deb11u1 amd64 [installed,automatic]
&gt; gpg-wks-client/stable,now 2.2.27-2+deb11u1 amd64 [installed,automatic]
&gt; gpg-wks-server/stable,now 2.2.27-2+deb11u1 amd64 [installed,automatic]
&gt; gpg/stable,now 2.2.27-2+deb11u1 amd64 [installed,automatic]
&gt; gpgconf/stable,now 2.2.27-2+deb11u1 amd64 [installed,automatic]
&gt; gpgsm/stable,now 2.2.27-2+deb11u1 amd64 [installed,automatic]
&gt; gpgv/stable,now 2.2.27-2+deb11u1 amd64 [installed]
127c126
&lt; gtk-update-icon-cache/now 3.24.24-4 amd64 [installed,upgradable to: 3.24.24-4+deb11u2]
---
&gt; gtk-update-icon-cache/stable,now 3.24.24-4+deb11u2 amd64 [installed,automatic]
132,133c131,132
&lt; gzip/stable,now 1.10-4 amd64 [installed,upgradable to: 1.10-4+deb11u1]
&lt; hardened-malloc/now 10-3 amd64 [installed,upgradable to: 0:11.1-1]
---
&gt; gzip/stable-security,now 1.10-4+deb11u1 amd64 [installed]
&gt; hardened-malloc/unknown,now 0:11.1-1 amd64 [installed,automatic]
135c134
&lt; helper-scripts/now 3:16.5-1 all [installed,upgradable to: 3:17.1-1]
---
&gt; helper-scripts/unknown,now 3:17.1-1 all [installed,automatic]
138a138
&gt; icon-pack-dist/unknown,now 3:3.5-1 all [installed,automatic]
144a145
&gt; initializer-dist/unknown,now 3:6.0-1 all [installed,automatic]
147a149
&gt; iotop/stable,now 0.6-24-g733f3f8-1.1 amd64 [installed,automatic]
156,157c158,160
&lt; kicksecure-dependencies-cli/now 3:24.1-1 all [installed,upgradable to: 3:24.6-1]
&lt; kicksecure-desktop-applications-xfce/now 3:24.1-1 all [installed,upgradable to: 3:24.6-1]
---
&gt; kicksecure-dependencies-cli/unknown,now 3:24.6-1 all [installed,automatic]
&gt; kicksecure-desktop-applications-xfce/unknown,now 3:24.6-1 all [installed,automatic]
&gt; kicksecure-recommended-cli/unknown,now 3:24.6-1 all [installed,automatic]
159a163
&gt; legacy-dist/unknown,now 3:13.2-1 all [installed,automatic]
166,167c170,171
&lt; libarchive-tools/now 3.4.3-2+b1 amd64 [installed,upgradable to: 3.4.3-2+deb11u1]
&lt; libarchive13/now 3.4.3-2+b1 amd64 [installed,upgradable to: 3.4.3-2+deb11u1]
---
&gt; libarchive-tools/stable,now 3.4.3-2+deb11u1 amd64 [installed,automatic]
&gt; libarchive13/stable,now 3.4.3-2+deb11u1 amd64 [installed,automatic]
189c193
&lt; libblkid1/now 2.36.1-8 amd64 [installed,upgradable to: 2.36.1-8+deb11u1]
---
&gt; libblkid1/stable,stable-security,now 2.36.1-8+deb11u1 amd64 [installed]
204,208c208,212
&lt; libc-bin/now 2.31-13+deb11u2 amd64 [installed,upgradable to: 2.31-13+deb11u3]
&lt; libc-dev-bin/now 2.31-13+deb11u2 amd64 [installed,upgradable to: 2.31-13+deb11u3]
&lt; libc-l10n/now 2.31-13+deb11u2 all [installed,upgradable to: 2.31-13+deb11u3]
&lt; libc6-dev/now 2.31-13+deb11u2 amd64 [installed,upgradable to: 2.31-13+deb11u3]
&lt; libc6/now 2.31-13+deb11u2 amd64 [installed,upgradable to: 2.31-13+deb11u3]
---
&gt; libc-bin/stable,now 2.31-13+deb11u3 amd64 [installed]
&gt; libc-dev-bin/stable,now 2.31-13+deb11u3 amd64 [installed,automatic]
&gt; libc-l10n/stable,now 2.31-13+deb11u3 all [installed]
&gt; libc6-dev/stable,now 2.31-13+deb11u3 amd64 [installed,automatic]
&gt; libc6/stable,now 2.31-13+deb11u3 amd64 [installed]
224c228
&lt; libcryptsetup12/now 2:2.3.5-1 amd64 [installed,upgradable to: 2:2.3.7-1+deb11u1]
---
&gt; libcryptsetup12/stable,stable-security,now 2:2.3.7-1+deb11u1 amd64 [installed]
227c231
&lt; libcups2/stable,now 2.3.3op2-3+deb11u1 amd64 [installed,upgradable to: 2.3.3op2-3+deb11u2]
---
&gt; libcups2/stable-security,now 2.3.3op2-3+deb11u2 amd64 [installed,automatic]
244c248
&lt; libdpkg-perl/stable,now 1.20.9 all [installed,upgradable to: 1.20.10]
---
&gt; libdpkg-perl/stable-security,now 1.20.10 all [installed,automatic]
269c273
&lt; libexpat1/now 2.2.10-2 amd64 [installed,upgradable to: 2.2.10-2+deb11u3]
---
&gt; libexpat1/stable,stable-security,now 2.2.10-2+deb11u3 amd64 [installed,automatic]
274c278
&lt; libfdisk1/now 2.36.1-8 amd64 [installed,upgradable to: 2.36.1-8+deb11u1]
---
&gt; libfdisk1/stable,stable-security,now 2.36.1-8+deb11u1 amd64 [installed]
281c285
&lt; libflac8/now 1.3.3-2 amd64 [installed,upgradable to: 1.3.3-2+deb11u1]
---
&gt; libflac8/stable,now 1.3.3-2+deb11u1 amd64 [installed,automatic]
323,324c327,328
&lt; libgtk-3-0/now 3.24.24-4 amd64 [installed,upgradable to: 3.24.24-4+deb11u2]
&lt; libgtk-3-common/now 3.24.24-4 all [installed,upgradable to: 3.24.24-4+deb11u2]
---
&gt; libgtk-3-0/stable,now 3.24.24-4+deb11u2 amd64 [installed,automatic]
&gt; libgtk-3-common/stable,now 3.24.24-4+deb11u2 all [installed,automatic]
351c355
&lt; libjavascriptcoregtk-4.0-18/now 2.34.3-1~deb11u1 amd64 [installed,upgradable to: 2.36.3-1~deb11u1]
---
&gt; libjavascriptcoregtk-4.0-18/stable-security,now 2.36.3-1~deb11u1 amd64 [installed,automatic]
370c374
&lt; libldap-2.4-2/stable,now 2.4.57+dfsg-3 amd64 [installed,upgradable to: 2.4.57+dfsg-3+deb11u1]
---
&gt; libldap-2.4-2/stable-security,now 2.4.57+dfsg-3+deb11u1 amd64 [installed,automatic]
381c385
&lt; liblzma5/stable,now 5.2.5-2 amd64 [installed,upgradable to: 5.2.5-2.1~deb11u1]
---
&gt; liblzma5/stable-security,now 5.2.5-2.1~deb11u1 amd64 [installed]
393c397
&lt; libmount1/now 2.36.1-8 amd64 [installed,upgradable to: 2.36.1-8+deb11u1]
---
&gt; libmount1/stable,stable-security,now 2.36.1-8+deb11u1 amd64 [installed]
420c424
&lt; libnss3/now 2:3.61-1+deb11u1 amd64 [installed,upgradable to: 2:3.61-1+deb11u2]
---
&gt; libnss3/stable,stable-security,now 2:3.61-1+deb11u2 amd64 [installed,automatic]
423a428
&gt; libopengl0/stable,now 1.3.2-1 amd64 [installed,automatic]
431c436
&lt; libpam-systemd/now 247.3-6 amd64 [installed,upgradable to: 247.3-7]
---
&gt; libpam-systemd/stable,now 247.3-7 amd64 [installed,automatic]
451,452c456,457
&lt; libpolkit-agent-1-0/now 0.105-31 amd64 [installed,upgradable to: 0.105-31+deb11u1]
&lt; libpolkit-gobject-1-0/now 0.105-31 amd64 [installed,upgradable to: 0.105-31+deb11u1]
---
&gt; libpolkit-agent-1-0/stable,stable-security,now 0.105-31+deb11u1 amd64 [installed,automatic]
&gt; libpolkit-gobject-1-0/stable,stable-security,now 0.105-31+deb11u1 amd64 [installed,automatic]
463c468
&lt; libqrexec-utils2/now 4.1.16-1+deb11u1 amd64 [installed,upgradable to: 4.1.18-1+deb11u1]
---
&gt; libqrexec-utils2/unknown,now 4.1.18-1+deb11u1 amd64 [installed,automatic]
480c485
&lt; libqubesdb/now 4.1.12-1+deb11u1 amd64 [installed,upgradable to: 4.1.13-1+deb11u1]
---
&gt; libqubesdb/unknown,now 4.1.13-1+deb11u1 amd64 [installed,automatic]
493,494c498,499
&lt; libsasl2-2/now 2.1.27+dfsg-2.1 amd64 [installed,upgradable to: 2.1.27+dfsg-2.1+deb11u1]
&lt; libsasl2-modules-db/now 2.1.27+dfsg-2.1 amd64 [installed,upgradable to: 2.1.27+dfsg-2.1+deb11u1]
---
&gt; libsasl2-2/stable,stable-security,now 2.1.27+dfsg-2.1+deb11u1 amd64 [installed,automatic]
&gt; libsasl2-modules-db/stable,stable-security,now 2.1.27+dfsg-2.1+deb11u1 amd64 [installed,automatic]
509c514
&lt; libsmartcols1/now 2.36.1-8 amd64 [installed,upgradable to: 2.36.1-8+deb11u1]
---
&gt; libsmartcols1/stable,stable-security,now 2.36.1-8+deb11u1 amd64 [installed]
520c525
&lt; libssl1.1/now 1.1.1k-1+deb11u1 amd64 [installed,upgradable to: 1.1.1n-0+deb11u2]
---
&gt; libssl1.1/stable-security,now 1.1.1n-0+deb11u2 amd64 [installed]
524c529
&lt; libsystemd0/now 247.3-6 amd64 [installed,upgradable to: 247.3-7]
---
&gt; libsystemd0/stable,now 247.3-7 amd64 [installed]
536c541
&lt; libtiff5/stable,now 4.2.0-1 amd64 [installed,upgradable to: 4.2.0-1+deb11u1]
---
&gt; libtiff5/stable-security,now 4.2.0-1+deb11u1 amd64 [installed,automatic]
545c550
&lt; libudev1/now 247.3-6 amd64 [installed,upgradable to: 247.3-7]
---
&gt; libudev1/stable,now 247.3-7 amd64 [installed]
553c558
&lt; libuuid1/now 2.36.1-8 amd64 [installed,upgradable to: 2.36.1-8+deb11u1]
---
&gt; libuuid1/stable,stable-security,now 2.36.1-8+deb11u1 amd64 [installed]
574c579
&lt; libwebkit2gtk-4.0-37/now 2.34.3-1~deb11u1 amd64 [installed,upgradable to: 2.36.3-1~deb11u1]
---
&gt; libwebkit2gtk-4.0-37/stable-security,now 2.36.3-1~deb11u1 amd64 [installed,automatic]
615,624c620,629
&lt; libxencall1/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
&lt; libxendevicemodel1/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
&lt; libxenevtchn1/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
&lt; libxenforeignmemory1/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
&lt; libxengnttab1/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
&lt; libxenhypfs1/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
&lt; libxenmisc4.14/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
&lt; libxenstore3.0/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
&lt; libxentoolcore1/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
&lt; libxentoollog1/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
---
&gt; libxencall1/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
&gt; libxendevicemodel1/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
&gt; libxenevtchn1/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
&gt; libxenforeignmemory1/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
&gt; libxengnttab1/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
&gt; libxenhypfs1/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
&gt; libxenmisc4.14/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
&gt; libxenstore3.0/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
&gt; libxentoolcore1/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
&gt; libxentoollog1/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
639c644
&lt; libxml2/now 2.9.10+dfsg-6.7 amd64 [installed,upgradable to: 2.9.10+dfsg-6.7+deb11u2]
---
&gt; libxml2/stable-security,now 2.9.10+dfsg-6.7+deb11u2 amd64 [installed,automatic]
662,663c667,668
&lt; linux-libc-dev/now 5.10.84-1 amd64 [installed,upgradable to: 5.10.113-1]
&lt; locales/now 2.31-13+deb11u2 all [installed,upgradable to: 2.31-13+deb11u3]
---
&gt; linux-libc-dev/stable-security,now 5.10.113-1 amd64 [installed,automatic]
&gt; locales/stable,now 2.31-13+deb11u3 all [installed]
680c685
&lt; mount/now 2.36.1-8 amd64 [installed,upgradable to: 2.36.1-8+deb11u1]
---
&gt; mount/stable,stable-security,now 2.36.1-8+deb11u1 amd64 [installed]
682,683c687,688
&lt; msgcollector-gui/now 3:8.0-1 all [installed,upgradable to: 3:8.3-1]
&lt; msgcollector/now 3:8.0-1 all [installed,upgradable to: 3:8.3-1]
---
&gt; msgcollector-gui/unknown,now 3:8.3-1 all [installed,automatic]
&gt; msgcollector/unknown,now 3:8.3-1 all [installed,automatic]
689a695
&gt; netcat-openbsd/stable,now 1.217-3 amd64 [installed,automatic]
693c699
&lt; onion-grater/now 3:10.2-1 all [installed,upgradable to: 3:10.4-1]
---
&gt; onion-grater/unknown,now 3:10.4-1 all [installed,automatic]
695,696c701,702
&lt; open-link-confirmation/now 3:4.8-1 all [installed,upgradable to: 3:4.9-1]
&lt; openssl/now 1.1.1k-1+deb11u1 amd64 [installed,upgradable to: 1.1.1n-0+deb11u2]
---
&gt; open-link-confirmation/unknown,now 3:4.9-1 all [installed,automatic]
&gt; openssl/stable-security,now 1.1.1n-0+deb11u2 amd64 [installed]
710c716
&lt; policykit-1/now 0.105-31 amd64 [installed,upgradable to: 0.105-31+deb11u1]
---
&gt; policykit-1/stable,stable-security,now 0.105-31+deb11u1 amd64 [installed,automatic]
753c759
&lt; python3-qubesdb/now 4.1.12-1+deb11u1 amd64 [installed,upgradable to: 4.1.13-1+deb11u1]
---
&gt; python3-qubesdb/unknown,now 4.1.13-1+deb11u1 amd64 [installed,automatic]
769,776c775,782
&lt; qubes-core-agent-dom0-updates/now 4.1.31-1+deb11u1 amd64 [installed,upgradable to: 4.1.35-1+deb11u1]
&lt; qubes-core-agent-nautilus/now 4.1.31-1+deb11u1 amd64 [installed,upgradable to: 4.1.35-1+deb11u1]
&lt; qubes-core-agent-networking/now 4.1.31-1+deb11u1 amd64 [installed,upgradable to: 4.1.35-1+deb11u1]
&lt; qubes-core-agent-passwordless-root/now 4.1.31-1+deb11u1 amd64 [installed,upgradable to: 4.1.35-1+deb11u1]
&lt; qubes-core-agent-thunar/now 4.1.31-1+deb11u1 amd64 [installed,upgradable to: 4.1.35-1+deb11u1]
&lt; qubes-core-agent/now 4.1.31-1+deb11u1 amd64 [installed,upgradable to: 4.1.35-1+deb11u1]
&lt; qubes-core-qrexec/now 4.1.16-1+deb11u1 amd64 [installed,upgradable to: 4.1.18-1+deb11u1]
&lt; qubes-gui-agent/now 4.1.24-1+deb11u1 amd64 [installed,upgradable to: 4.1.25-1+deb11u1]
---
&gt; qubes-core-agent-dom0-updates/unknown,now 4.1.35-1+deb11u1 amd64 [installed,automatic]
&gt; qubes-core-agent-nautilus/unknown,now 4.1.35-1+deb11u1 amd64 [installed,automatic]
&gt; qubes-core-agent-networking/unknown,now 4.1.35-1+deb11u1 amd64 [installed,automatic]
&gt; qubes-core-agent-passwordless-root/unknown,now 4.1.35-1+deb11u1 amd64 [installed,automatic]
&gt; qubes-core-agent-thunar/unknown,now 4.1.35-1+deb11u1 amd64 [installed,automatic]
&gt; qubes-core-agent/unknown,now 4.1.35-1+deb11u1 amd64 [installed,automatic]
&gt; qubes-core-qrexec/unknown,now 4.1.18-1+deb11u1 amd64 [installed,automatic]
&gt; qubes-gui-agent/unknown,now 4.1.25-1+deb11u1 amd64 [installed,automatic]
783,788c789,794
&lt; qubes-whonix-gateway-packages-recommended/now 1:17.1-1 all [installed,upgradable to: 1:17.3-1]
&lt; qubes-whonix-gateway/now 3:22.2-1 all [installed,upgradable to: 3:22.5-1]
&lt; qubes-whonix-shared-packages-recommended/now 1:17.1-1 all [installed,upgradable to: 1:17.3-1]
&lt; qubes-whonix/now 1:17.1-1 all [installed,upgradable to: 1:17.3-1]
&lt; qubesdb-vm/now 4.1.12-1+deb11u1 amd64 [installed,upgradable to: 4.1.13-1+deb11u1]
&lt; qubesdb/now 4.1.12-1+deb11u1 amd64 [installed,upgradable to: 4.1.13-1+deb11u1]
---
&gt; qubes-whonix-gateway-packages-recommended/unknown,now 1:17.3-1 all [installed,automatic]
&gt; qubes-whonix-gateway/unknown,now 3:22.5-1 all [installed]
&gt; qubes-whonix-shared-packages-recommended/unknown,now 1:17.3-1 all [installed,automatic]
&gt; qubes-whonix/unknown,now 1:17.3-1 all [installed,automatic]
&gt; qubesdb-vm/unknown,now 4.1.13-1+deb11u1 amd64 [installed,automatic]
&gt; qubesdb/unknown,now 4.1.13-1+deb11u1 amd64 [installed,automatic]
790,791c796,797
&lt; repository-dist-wizard/now 3:8.6-1 all [installed,upgradable to: 3:8.8-1]
&lt; repository-dist/now 3:8.6-1 all [installed,upgradable to: 3:8.8-1]
---
&gt; repository-dist-wizard/unknown,now 3:8.8-1 all [installed,automatic]
&gt; repository-dist/unknown,now 3:8.8-1 all [installed,automatic]
796c802
&lt; rsyslog/stable,now 8.2102.0-2 amd64 [installed,upgradable to: 8.2102.0-2+deb11u1]
---
&gt; rsyslog/stable-security,now 8.2102.0-2+deb11u1 amd64 [installed]
800,801c806,807
&lt; sdwdate-gui/now 1:8.0-1 all [installed,upgradable to: 1:8.2-1]
&lt; sdwdate/now 3:19.1-1 all [installed,upgradable to: 3:19.7-1]
---
&gt; sdwdate-gui/unknown,now 1:8.2-1 all [installed,automatic]
&gt; sdwdate/unknown,now 3:19.7-1 all [installed,automatic]
803c809
&lt; security-misc/now 3:22.9-1 all [installed,upgradable to: 3:23.1-1]
---
&gt; security-misc/unknown,now 3:23.1-1 all [installed,automatic]
806,807c812,813
&lt; setup-dist/now 3:6.8-1 all [installed,upgradable to: 3:7.1-1]
&lt; setup-wizard-dist/now 3:7.4-1 all [installed,upgradable to: 3:7.8-1]
---
&gt; setup-dist/unknown,now 3:7.1-1 all [installed,automatic]
&gt; setup-wizard-dist/unknown,now 3:7.8-1 all [installed,automatic]
818,821c824,827
&lt; systemcheck/now 3:24.2-1 all [installed,upgradable to: 3:24.7-1]
&lt; systemd-sysv/now 247.3-6 amd64 [installed,upgradable to: 247.3-7]
&lt; systemd/now 247.3-6 amd64 [installed,upgradable to: 247.3-7]
&lt; sysvinit-utils/now 2.96-7 amd64 [installed,upgradable to: 2.96-7+deb11u1]
---
&gt; systemcheck/unknown,now 3:24.7-1 all [installed,automatic]
&gt; systemd-sysv/stable,now 247.3-7 amd64 [installed]
&gt; systemd/stable,now 247.3-7 amd64 [installed]
&gt; sysvinit-utils/stable,now 2.96-7+deb11u1 amd64 [installed]
823,824c829,830
&lt; tasksel-data/now 3.68 all [installed,upgradable to: 3.68+deb11u1]
&lt; tasksel/now 3.68 all [installed,upgradable to: 3.68+deb11u1]
---
&gt; tasksel-data/stable,now 3.68+deb11u1 all [installed]
&gt; tasksel/stable,now 3.68+deb11u1 all [installed]
829c835
&lt; timesanitycheck/now 3:5.0-1 all [installed,upgradable to: 3:5.2-1]
---
&gt; timesanitycheck/unknown,now 3:5.2-1 all [installed,automatic]
832,834c838,841
&lt; tor-control-panel/now 1:3.5-1 all [installed,upgradable to: 1:4.1-1]
&lt; tor-geoipdb/now 0.4.6.9-1~d11.bullseye+1 all [installed,upgradable to: 0.4.7.7-1~d11.bullseye+1]
&lt; tor/now 0.4.6.9-1~d11.bullseye+1 amd64 [installed,upgradable to: 0.4.7.7-1~d11.bullseye+1]
---
&gt; tor-control-panel/unknown,now 1:4.1-1 all [installed,automatic]
&gt; tor-ctrl/unknown,now 3:4.7-1 all [installed,automatic]
&gt; tor-geoipdb/unknown,now 0.4.7.7-1~d11.bullseye+1 all [installed,automatic]
&gt; tor/unknown,now 0.4.7.7-1~d11.bullseye+1 amd64 [installed,automatic]
836c843
&lt; tzdata/stable,now 2021a-1+deb11u2 all [installed,upgradable to: 2021a-1+deb11u3]
---
&gt; tzdata/stable-updates,now 2021a-1+deb11u3 all [installed]
838c845
&lt; udev/now 247.3-6 amd64 [installed,upgradable to: 247.3-7]
---
&gt; udev/stable,now 247.3-7 amd64 [installed]
842c849
&lt; usability-misc/now 3:10.1-1 all [installed,upgradable to: 3:10.4-1]
---
&gt; usability-misc/unknown,now 3:10.4-1 all [installed,automatic]
844,845c851,852
&lt; util-linux/now 2.36.1-8 amd64 [installed,upgradable to: 2.36.1-8+deb11u1]
&lt; uwt/now 3:6.9-1 all [installed,upgradable to: 3:7.0-1]
---
&gt; util-linux/stable,stable-security,now 2.36.1-8+deb11u1 amd64 [installed]
&gt; uwt/unknown,now 3:7.0-1 all [installed,automatic]
849c856
&lt; vm-config-dist/now 3:7.9-1 all [installed,upgradable to: 3:8.0-1]
---
&gt; vm-config-dist/unknown,now 3:8.0-1 all [installed,automatic]
853,864c860,869
&lt; whonix-base-files/now 3:8.4-1 all [installed,upgradable to: 3:8.5-1]
&lt; whonix-firewall/now 3:10.9-1 all [installed,upgradable to: 3:11.1-1]
&lt; whonix-gateway-default-applications-gui/now 3:22.2-1 all [installed,upgradable to: 3:22.5-1]
&lt; whonix-gateway-packages-dependencies-cli/now 3:22.2-1 all [installed,upgradable to: 3:22.5-1]
&lt; whonix-gateway-packages-dependencies-pre/now 3:22.2-1 all [installed,upgradable to: 3:22.5-1]
&lt; whonix-gateway-shared-packages-shared-meta/now 3:22.2-1 all [installed,upgradable to: 3:22.5-1]
&lt; whonix-gw-network-conf/now 3:4.4-1 all [installed,upgradable to: 3:4.5-1]
&lt; whonix-initializer/now 3:5.9-1 all [installed,local]
&lt; whonix-legacy/now 3:12.9-1 all [installed,local]
&lt; whonix-shared-default-applications-gui/now 3:22.2-1 all [installed,upgradable to: 3:22.5-1]
&lt; whonix-shared-packages-dependencies-cli/now 3:22.2-1 all [installed,upgradable to: 3:22.5-1]
&lt; whonix-shared-packages-recommended-cli/now 3:22.2-1 all [installed,upgradable to: 3:22.5-1]
---
&gt; whonix-base-files/unknown,now 3:8.5-1 all [installed,automatic]
&gt; whonix-firewall/unknown,now 3:11.1-1 all [installed,automatic]
&gt; whonix-gateway-default-applications-gui/unknown,now 3:22.5-1 all [installed,automatic]
&gt; whonix-gateway-packages-dependencies-cli/unknown,now 3:22.5-1 all [installed,automatic]
&gt; whonix-gateway-packages-dependencies-pre/unknown,now 3:22.5-1 all [installed,automatic]
&gt; whonix-gateway-shared-packages-shared-meta/unknown,now 3:22.5-1 all [installed,automatic]
&gt; whonix-gw-network-conf/unknown,now 3:4.5-1 all [installed,automatic]
&gt; whonix-shared-default-applications-gui/unknown,now 3:22.5-1 all [installed,automatic]
&gt; whonix-shared-packages-dependencies-cli/unknown,now 3:22.5-1 all [installed,automatic]
&gt; whonix-shared-packages-recommended-cli/unknown,now 3:22.5-1 all [installed,automatic]
878,881c883,886
&lt; xen-utils-4.14/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
&lt; xen-utils-common/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
&lt; xen-utils-guest/now 4.14.3-7+deb11u1 amd64 [installed,upgradable to: 4.14.4-4+deb11u1]
&lt; xenstore-utils/stable,now 4.14.3+32-g9de3671772-1~deb11u1 amd64 [installed,upgradable to: 4.14.4+74-gd7b22226b5-1]
---
&gt; xen-utils-4.14/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
&gt; xen-utils-common/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
&gt; xen-utils-guest/unknown,now 4.14.4-4+deb11u1 amd64 [installed,automatic]
&gt; xenstore-utils/stable-security,now 4.14.4+74-gd7b22226b5-1 amd64 [installed,automatic]
888,891c893,896
&lt; xserver-xorg-input-qubes/now 4.1.24-1+deb11u1 amd64 [installed,upgradable to: 4.1.25-1+deb11u1]
&lt; xserver-xorg-qubes-common/now 4.1.24-1+deb11u1 amd64 [installed,upgradable to: 4.1.25-1+deb11u1]
&lt; xserver-xorg-video-dummyqbs/now 4.1.24-1+deb11u1 amd64 [installed,upgradable to: 4.1.25-1+deb11u1]
&lt; xterm/now 366-1 amd64 [installed,upgradable to: 366-1+deb11u1]
---
&gt; xserver-xorg-input-qubes/unknown,now 4.1.25-1+deb11u1 amd64 [installed,automatic]
&gt; xserver-xorg-qubes-common/unknown,now 4.1.25-1+deb11u1 amd64 [installed,automatic]
&gt; xserver-xorg-video-dummyqbs/unknown,now 4.1.25-1+deb11u1 amd64 [installed,automatic]
&gt; xterm/stable,now 366-1+deb11u1 amd64 [installed]
893c898
&lt; xz-utils/stable,now 5.2.5-2 amd64 [installed,upgradable to: 5.2.5-2.1~deb11u1]
---
&gt; xz-utils/stable-security,now 5.2.5-2.1~deb11u1 amd64 [installed,automatic]
897,899c902,904
&lt; zlib1g/stable,now 1:1.2.11.dfsg-2 amd64 [installed,upgradable to: 1:1.2.11.dfsg-2+deb11u1]
&lt; zsh-common/now 5.8-6 all [installed,upgradable to: 5.8-6+deb11u1]
&lt; zsh/now 5.8-6+b2 amd64 [installed,upgradable to: 5.8-6+deb11u1]
---
&gt; zlib1g/stable-security,now 1:1.2.11.dfsg-2+deb11u1 amd64 [installed]
&gt; zsh-common/stable,stable-security,now 5.8-6+deb11u1 all [installed,auto-removable]
&gt; zsh/stable,stable-security,now 5.8-6+deb11u1 amd64 [installed,auto-removable]
</code></pre>
          <p><a href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/7">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/7</link>
        <pubDate>Fri, 10 Jun 2022 20:42:14 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-13759-7</guid>
        <source url="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss">sys-whonix (sdwdate) not properly resuming from suspend</source>
      </item>
      <item>
        <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
        <dc:creator><![CDATA[tlaurion]]></dc:creator>
        <description><![CDATA[
            <p><a class="mention" href="http://forums.whonix.org/u/marmarek">@marmarek</a> said: started build of kernel 5.10.121, with clocksource change reverted; will be in testing repo in few hours.</p>
<aside class="onebox githubcommit" data-onebox-src="https://github.com/QubesOS/qubes-linux-kernel/commit/3a84c17380ae394e9c4837931fe515b876d064c1">
  <header class="source">

      <a href="https://github.com/QubesOS/qubes-linux-kernel/commit/3a84c17380ae394e9c4837931fe515b876d064c1" target="_blank" rel="noopener nofollow ugc">github.com/QubesOS/qubes-linux-kernel</a>
  </header>

  <article class="onebox-body">
    <div class="github-row">
  <div class="github-icon-container" title="Commit">
    <svg width="60" height="60" class="github-icon" viewBox="0 0 14 16" aria-hidden="true"><path d="M10.86 7c-.45-1.72-2-3-3.86-3-1.86 0-3.41 1.28-3.86 3H0v2h3.14c.45 1.72 2 3 3.86 3 1.86 0 3.41-1.28 3.86-3H14V7h-3.14zM7 10.2c-1.22 0-2.2-.98-2.2-2.2 0-1.22.98-2.2 2.2-2.2 1.22 0 2.2.98 2.2 2.2 0 1.22-.98 2.2-2.2 2.2z"></path></svg>
  </div>

  <div class="github-info-container">
    <h4>
      <a href="https://github.com/QubesOS/qubes-linux-kernel/commit/3a84c17380ae394e9c4837931fe515b876d064c1" target="_blank" rel="noopener nofollow ugc">Revert "Switch default clocksource to 'tsc'"</a>
    </h4>

    <div class="github-info">
      <div class="date">
        committed <span class="discourse-local-date" data-format="ll" data-date="2022-06-10" data-time="19:30:31" data-timezone="UTC">07:30PM - 10 Jun 22 UTC</span>
      </div>

      <div class="user">
        <a href="https://github.com/marmarek" target="_blank" rel="noopener nofollow ugc">
          <img alt="marmarek" src="https://avatars.githubusercontent.com/u/726704?v=4" class="onebox-avatar-inline" width="20" height="20">
          marmarek
        </a>
      </div>

      <div class="lines" title="changed 1 files with 0 additions and 1 deletions">
        <a href="https://github.com/QubesOS/qubes-linux-kernel/commit/3a84c17380ae394e9c4837931fe515b876d064c1" target="_blank" rel="noopener nofollow ugc">
          <span class="added">+0</span>
          <span class="removed">-1</span>
        </a>
      </div>
    </div>
  </div>
</div>

  <div class="github-row">
    <p class="github-body-container">This causes issues with Whonix on resume.
Report from @tlaurion:
https://forums.<span class="show-more-container"><a href="https://github.com/QubesOS/qubes-linux-kernel/commit/3a84c17380ae394e9c4837931fe515b876d064c1" target="_blank" rel="noopener nofollow ugc" class="show-more">‚Ä¶</a></span><span class="excerpt hidden">whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/4
And from @jevank:
https://github.com/QubesOS/qubes-issues/issues/7404#issuecomment-1113299850

This reverts commit d0a6fe5c5b7b0e4191f7c5d463adfcba9862242f.</span></p>
  </div>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both"></div>
</aside>

          <p><a href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/6">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/6</link>
        <pubDate>Fri, 10 Jun 2022 19:58:30 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-13759-6</guid>
        <source url="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss">sys-whonix (sdwdate) not properly resuming from suspend</source>
      </item>
      <item>
        <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
        <dc:creator><![CDATA[tlaurion]]></dc:creator>
        <description><![CDATA[
            <aside class="quote no-group" data-username="marmarek" data-post="4" data-topic="13759">
<div class="title">
<div class="quote-controls"></div>
<img alt="" width="20" height="20" src="//forums.whonix.org/letter_avatar_proxy/v4/letter/m/df705f/40.png" class="avatar"> marmarek:</div>
<blockquote>
<p>But even on first resume, it doesn‚Äôt result in swapping / 100%CPU in sys-firewall, right? There must be some specific interaction with Whonix that makes it this bad (my bet is on sdwdate).</p>
</blockquote>
</aside>
<p>Nope. Timestamps under sys-whonix are litterally frozen for 10 minutes on resume.</p>
<p>sys-firewall log extract for timestamps:</p>
<pre><code class="lang-auto">Jun 10 15:39:12 sys-firewall qrexec-agent[1083]: 2022-06-10 15:39:12.552 qrexec-agent[1083]: qrexec-agent-data.c:244:handle_new_process_common: executed: root:QUBESRPC qubes.SuspendPreAll dom0 (pid 1085)
Jun 10 15:39:22 sys-firewall qrexec-agent[1131]: 2022-06-10 15:39:22.151 qrexec-agent[1131]: qrexec-agent-data.c:244:handle_new_process_common: executed: root:QUBESRPC qubes.SuspendPostAll dom0 (pid 1133)
Jun 10 15:39:55 sys-firewall audit[1]: SERVICE_STOP pid=1 uid=0 auid=4294967295 ses=4294967295 msg='unit=qubes-sync-time comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
Jun 10 15:39:55 sys-firewall kernel: audit: type=1131 audit(1654889995.059:150): pid=1 uid=0 auid=4294967295 ses=4294967295 msg='unit=qubes-sync-time comm="systemd" exe="/usr/lib/systemd/systemd" hostname=? addr=? terminal=? res=success'
Jun 10 15:39:55 sys-firewall kernel: clocksource: timekeeping watchdog on CPU0: Marking clocksource 'tsc' as unstable because the skew is too large:
Jun 10 15:39:55 sys-firewall kernel: clocksource:                       'xen' wd_now: 6eabada90a7 wd_last: 6e76127152d mask: ffffffffffffffff
Jun 10 15:39:55 sys-firewall kernel: clocksource:                       'tsc' cs_now: fffffefc75a01aa2 cs_last: 10ca9accd19 mask: ffffffffffffffff
Jun 10 15:39:55 sys-firewall kernel: tsc: Marking TSC unstable due to clocksource watchdog
Jun 10 15:39:55 sys-firewall kernel: clocksource: Checking clocksource tsc synchronization from CPU 1.
Jun 10 15:39:55 sys-firewall kernel: clocksource: Override clocksource tsc is unstable and not HRT compatible - cannot switch while in HRT/NOHZ mode
Jun 10 15:39:55 sys-firewall kernel: clocksource: Switched to clocksource xen
</code></pre>
<p>sys-whonix:</p>
<pre><code class="lang-auto">Jun 10 17:38:56 host qrexec-agent[2084]: 2022-06-10 17:38:56.129 qrexec-agent[2084]: qrexec-agent-data.c:244:handle_new_process_common: executed: root:QUBESRPC qubes.SuspendPreAll dom0 (pid 2086)
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + set -e
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + '[' -f /run/qubes/this-is-templatevm ']'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ id -u
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + '[' '!' 0 = 0 ']'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + command -v qubesdb-read
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + true
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + mkdir --parents /run/sdwdate
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + chown --recursive sdwdate:sdwdate /run/sdwdate
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + systemctl --no-pager status sdwdate
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + output_cmd 'INFO - Creating /run/sdwdate/sdwdate_was_running.status...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date_cmd
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date --utc '+%Y-%m-%d %T'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + msg='2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Creating /run/sdwdate/sdwdate_was_running.status...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Creating /run/sdwdate/sdwdate_was_running.status...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Creating /run/sdwdate/sdwdate_was_running.status...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + systemd-cat --identifier=suspend-pre
Jun 10 17:38:56 host suspend-pre[2123]: 2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Creating /run/sdwdate/sdwdate_was_running.status...
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + touch /run/sdwdate/sdwdate_was_running.status
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + output_cmd 'INFO - Done, created /run/sdwdate/sdwdate_was_running.status.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date_cmd
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date --utc '+%Y-%m-%d %T'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + msg='2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, created /run/sdwdate/sdwdate_was_running.status.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, created /run/sdwdate/sdwdate_was_running.status.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, created /run/sdwdate/sdwdate_was_running.status.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + systemd-cat --identifier=suspend-pre
Jun 10 17:38:56 host suspend-pre[2127]: 2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, created /run/sdwdate/sdwdate_was_running.status.
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + output_cmd 'INFO - Stopping sdwdate...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date_cmd
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date --utc '+%Y-%m-%d %T'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + msg='2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Stopping sdwdate...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Stopping sdwdate...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + systemd-cat --identifier=suspend-pre
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Stopping sdwdate...'
Jun 10 17:38:56 host suspend-pre[2130]: 2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Stopping sdwdate...
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + systemctl --no-pager stop sdwdate
Jun 10 17:38:56 host systemd[1]: Stopping Secure Distributed Web Date...
Jun 10 17:38:56 host sdwdate[823]: 2022-06-10 17:38:56 - sdwdate - INFO - Signal SIGTERM received.
Jun 10 17:38:56 host sdwdate[823]: 2022-06-10 17:38:56 - sdwdate - INFO - Exiting with exit_code '143' because or reason 'signal_handler called'.
Jun 10 17:38:56 host sdwdate[823]: 2022-06-10 17:38:56 - sdwdate - INFO - sdwdate stopped by user or system.
Jun 10 17:38:56 host sdwdate[823]: 2022-06-10 17:38:56 - sdwdate - INFO - sclockadj process not running, ok.
Jun 10 17:38:56 host sdwdate[823]: 2022-06-10 17:38:56 - sdwdate - INFO - Terminated sleep process.
Jun 10 17:38:56 host sdwdate[823]: 2022-06-10 17:38:56 - sdwdate - INFO - End.
Jun 10 17:38:56 host systemd[1]: sdwdate.service: Succeeded.
Jun 10 17:38:56 host systemd[1]: Stopped Secure Distributed Web Date.
Jun 10 17:38:56 host systemd[1]: sdwdate.service: Consumed 17.836s CPU time.
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + output_cmd 'INFO - Done, stopped sdwdate.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date_cmd
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date --utc '+%Y-%m-%d %T'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + msg='2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, stopped sdwdate.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, stopped sdwdate.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, stopped sdwdate.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + systemd-cat --identifier=suspend-pre
Jun 10 17:38:56 host suspend-pre[2136]: 2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, stopped sdwdate.
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + output_cmd 'INFO - Deleting /run/sdwdate/first_success...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date_cmd
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date --utc '+%Y-%m-%d %T'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + msg='2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Deleting /run/sdwdate/first_success...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Deleting /run/sdwdate/first_success...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Deleting /run/sdwdate/first_success...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + systemd-cat --identifier=suspend-pre
Jun 10 17:38:56 host suspend-pre[2139]: 2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Deleting /run/sdwdate/first_success...
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + rm --force /run/sdwdate/first_success
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + output_cmd 'INFO - Done, deleted /run/sdwdate/first_success.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date_cmd
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date --utc '+%Y-%m-%d %T'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + msg='2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, deleted /run/sdwdate/first_success.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, deleted /run/sdwdate/first_success.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + systemd-cat --identifier=suspend-pre
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, deleted /run/sdwdate/first_success.'
Jun 10 17:38:56 host suspend-pre[2143]: 2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, deleted /run/sdwdate/first_success.
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + output_cmd 'INFO - Deleting /run/sdwdate/success...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date_cmd
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date --utc '+%Y-%m-%d %T'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + msg='2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Deleting /run/sdwdate/success...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Deleting /run/sdwdate/success...'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + systemd-cat --identifier=suspend-pre
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Deleting /run/sdwdate/success...'
Jun 10 17:38:56 host suspend-pre[2146]: 2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Deleting /run/sdwdate/success...
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + rm --force /run/sdwdate/success
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + output_cmd 'INFO - Done, deleted /run/sdwdate/success.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date_cmd
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date --utc '+%Y-%m-%d %T'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + msg='2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, deleted /run/sdwdate/success.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, deleted /run/sdwdate/success.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, deleted /run/sdwdate/success.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + systemd-cat --identifier=suspend-pre
Jun 10 17:38:56 host suspend-pre[2150]: 2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, deleted /run/sdwdate/success.
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + command -v whonix_firewall
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + output_cmd 'INFO - Entering Whonix firewall timesync-fail-closed mode.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date_cmd
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: ++ date --utc '+%Y-%m-%d %T'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + msg='2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Entering Whonix firewall timesync-fail-closed mode.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Entering Whonix firewall timesync-fail-closed mode.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Entering Whonix firewall timesync-fail-closed mode.'
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + systemd-cat --identifier=suspend-pre
Jun 10 17:38:56 host suspend-pre[2153]: 2022-06-10 17:38:56 - /usr/libexec/sdwdate/suspend-pre - INFO - Entering Whonix firewall timesync-fail-closed mode.
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + firewall_mode=timesync-fail-closed
Jun 10 17:38:56 host qubes.SuspendPreAll-dom0[2113]: + whonix_firewall
Jun 10 17:38:57 host qubes.SuspendPreAll-dom0[2113]: + output_cmd 'INFO - Done, entered Whonix firewall timesync-fail-closed mode.'
Jun 10 17:38:57 host qubes.SuspendPreAll-dom0[2113]: ++ date_cmd
Jun 10 17:38:57 host qubes.SuspendPreAll-dom0[2113]: ++ date --utc '+%Y-%m-%d %T'
Jun 10 17:38:57 host qubes.SuspendPreAll-dom0[2113]: + msg='2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, entered Whonix firewall timesync-fail-closed mode.'
Jun 10 17:38:57 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, entered Whonix firewall timesync-fail-closed mode.'
Jun 10 17:38:57 host qubes.SuspendPreAll-dom0[2113]: + systemd-cat --identifier=suspend-pre
Jun 10 17:38:57 host qubes.SuspendPreAll-dom0[2113]: + echo '2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, entered Whonix firewall timesync-fail-closed mode.'
Jun 10 17:38:57 host suspend-pre[2290]: 2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-pre - INFO - Done, entered Whonix firewall timesync-fail-closed mode.
Jun 10 17:38:57 host qrexec-agent[2086]: pam_unix(qrexec:session): session closed for user root
Jun 10 17:38:57 host systemd[1]: session-c3.scope: Succeeded.
Jun 10 17:38:57 host qrexec-agent[2084]: 2022-06-10 17:38:57.430 qrexec-agent[2084]: qrexec-agent-data.c:272:handle_new_process_common: pid 2086 exited with 0
Jun 10 17:38:57 host sudo[2362]:     user : PWD=/home/user ; USER=root ; COMMAND=/usr/bin/journalctl --boot 0 -f
Jun 10 17:38:57 host qrexec-agent[2291]: 2022-06-10 17:38:57.614 qrexec-agent[2291]: qrexec-agent-data.c:244:handle_new_process_common: executed: root:QUBESRPC qubes.SuspendPostAll dom0 (pid 2293)
Jun 10 17:38:57 host qrexec-agent[2293]: pam_unix(qrexec:session): session opened for user root(uid=0) by (uid=0)
Jun 10 17:38:57 host sudo[2362]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=1000)
Jun 10 17:38:57 host sudo[2394]:     user : PWD=/home/user ; USER=root ; COMMAND=/usr/bin/journalctl --boot 0
Jun 10 17:38:57 host sudo[2394]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=1000)
Jun 10 17:38:57 host sudo[2394]: pam_unix(sudo:session): session closed for user root
Jun 10 17:38:57 host systemd[1]: Started Session c4 of user root.
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + set -e
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + '[' -f /run/qubes/this-is-templatevm ']'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: ++ id -u
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + '[' '!' 0 = 0 ']'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + command -v qubesdb-read
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + true
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + mkdir --parents /run/sdwdate
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + chown --recursive sdwdate:sdwdate /run/sdwdate
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + test -f /run/sdwdate/sdwdate_was_running.status
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + output_cmd 'INFO - Deleting /run/sdwdate/sdwdate_was_running.status...'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: ++ date_cmd
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: ++ date -u '+%Y-%m-%d %T'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + msg='2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Deleting /run/sdwdate/sdwdate_was_running.status...'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + echo '2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Deleting /run/sdwdate/sdwdate_was_running.status...'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + systemd-cat --identifier=suspend-post
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + echo '2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Deleting /run/sdwdate/sdwdate_was_running.status...'
Jun 10 17:38:57 host suspend-post[2313]: 2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Deleting /run/sdwdate/sdwdate_was_running.status...
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + rm --force /run/sdwdate/sdwdate_was_running.status
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + output_cmd 'INFO - Done, deleted /run/sdwdate/sdwdate_was_running.status.'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: ++ date_cmd
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: ++ date -u '+%Y-%m-%d %T'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + msg='2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Done, deleted /run/sdwdate/sdwdate_was_running.status.'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + echo '2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Done, deleted /run/sdwdate/sdwdate_was_running.status.'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + systemd-cat --identifier=suspend-post
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + echo '2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Done, deleted /run/sdwdate/sdwdate_was_running.status.'
Jun 10 17:38:57 host suspend-post[2317]: 2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Done, deleted /run/sdwdate/sdwdate_was_running.status.
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + output_cmd 'INFO - Running sdwdate-clock-jump...'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: ++ date_cmd
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: ++ date -u '+%Y-%m-%d %T'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + msg='2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Running sdwdate-clock-jump...'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + echo '2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Running sdwdate-clock-jump...'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + systemd-cat --identifier=suspend-post
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + echo '2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Running sdwdate-clock-jump...'
Jun 10 17:38:57 host suspend-post[2320]: 2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Running sdwdate-clock-jump...
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + sdwdate-clock-jump
Jun 10 17:38:57 host sudo[2327]:     root : PWD=/root ; USER=sdwdate ; COMMAND=/usr/bin/touch /run/sdwdate/clock_jump_do_once
Jun 10 17:38:57 host sudo[2327]: pam_unix(sudo:session): session opened for user sdwdate(uid=111) by (uid=0)
Jun 10 17:38:57 host sudo[2327]: pam_unix(sudo:session): session closed for user sdwdate
Jun 10 17:38:57 host systemd[1]: Starting Secure Distributed Web Date...
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + output_cmd 'INFO - Done, with sdwdate-clock-jump.'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: ++ date_cmd
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: ++ date -u '+%Y-%m-%d %T'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + msg='2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Done, with sdwdate-clock-jump.'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + echo '2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Done, with sdwdate-clock-jump.'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + echo '2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Done, with sdwdate-clock-jump.'
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + systemd-cat --identifier=suspend-post
Jun 10 17:38:57 host suspend-post[2333]: 2022-06-10 17:38:57 - /usr/libexec/sdwdate/suspend-post - INFO - Done, with sdwdate-clock-jump.
Jun 10 17:38:57 host qubes.SuspendPostAll-dom0[2304]: + exit 0
Jun 10 17:38:57 host systemd[1]: Condition check resulted in Update time from ClockVM being skipped.
Jun 10 17:38:57 host qrexec-agent[2293]: pam_unix(qrexec:session): session closed for user root
Jun 10 17:38:57 host qrexec-agent[2291]: 2022-06-10 17:38:57.614 qrexec-agent[2291]: qrexec-agent-data.c:272:handle_new_process_common: pid 2293 exited with 0
Jun 10 17:38:57 host sdwdate[2330]: 2022-06-10 17:38:57 - sdwdate - INFO - sdwdate started. PID: 2330
Jun 10 17:38:57 host systemd[1]: Started Secure Distributed Web Date.
Jun 10 17:38:57 host sdwdate[2330]: 2022-06-10 17:38:57 - sdwdate - INFO - Tor socks host: 127.0.0.1 Tor socks port: 9108
Jun 10 17:38:57 host sdwdate[2330]: 2022-06-10 17:38:57 - sdwdate - INFO - Running sdwdate main loop. iteration: 1 / 10000
Jun 10 17:38:57 host tinyproxy[782]: Proxying refused on filtered domain "127.0.0.1"
Jun 10 17:38:57 host sudo[2410]:     user : PWD=/home/user ; USER=root ; COMMAND=/usr/bin/journalctl --boot 0
Jun 10 17:38:57 host sudo[2410]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=1000)
Jun 10 17:38:57 host sudo[2410]: pam_unix(sudo:session): session closed for user root
Jun 10 17:38:57 host sudo[2456]:     user : PWD=/home/user ; USER=root ; COMMAND=/usr/bin/journalctl --boot 0
Jun 10 17:38:57 host sudo[2456]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=1000)
Jun 10 17:38:57 host sudo[2456]: pam_unix(sudo:session): session closed for user root
Jun 10 17:38:57 host sudo[2486]:     user : PWD=/home/user ; USER=root ; COMMAND=/usr/bin/journalctl --boot 1
Jun 10 17:38:57 host sudo[2486]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=1000)
Jun 10 17:38:57 host sudo[2486]: pam_unix(sudo:session): session closed for user root
Jun 10 17:38:57 host sudo[2502]:     user : PWD=/home/user ; USER=root ; COMMAND=/usr/bin/journalctl --boot 1
Jun 10 17:38:57 host sudo[2502]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=1000)
Jun 10 17:38:57 host sudo[2502]: pam_unix(sudo:session): session closed for user root
Jun 10 17:38:57 host sudo[2518]:     user : PWD=/home/user ; USER=root ; COMMAND=/usr/bin/journalctl --boot -1
Jun 10 17:38:57 host sudo[2518]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=1000)
Jun 10 17:38:57 host sudo[2518]: pam_unix(sudo:session): session closed for user root
Jun 10 17:38:58 host kernel: clocksource: timekeeping watchdog on CPU0: Marking clocksource 'tsc' as unstable because the skew is too large:
Jun 10 17:38:58 host kernel: clocksource:                       'xen' wd_now: f9d4b2a3a9 wd_last: 69052de169 mask: ffffffffffffffff
Jun 10 17:38:58 host kernel: clocksource:                       'tsc' cs_now: 8ab2519683 cs_last: 8a5c9b64e0 mask: ffffffffffffffff
Jun 10 17:38:58 host kernel: tsc: Marking TSC unstable due to clocksource watchdog
Jun 10 17:38:58 host kernel: clocksource: Checking clocksource tsc synchronization from CPU 0.
Jun 10 17:38:58 host kernel: clocksource: Override clocksource tsc is unstable and not HRT compatible - cannot switch while in HRT/NOHZ mode
Jun 10 17:38:58 host kernel: clocksource: Switched to clocksource xen
Jun 10 17:38:57 host systemd[1]: session-c4.scope: Succeeded.
Jun 10 17:39:08 host sdwdate[2330]: 2022-06-10 17:39:08 - sdwdate - INFO - PREPARATION:
Jun 10 17:39:08 host sdwdate[2330]: 2022-06-10 17:39:08 - sdwdate - INFO -
Jun 10 17:39:08 host sdwdate[2330]: __ ### START: ### /usr/libexec/helper-scripts/onion-time-pre-script
Jun 10 17:39:08 host sdwdate[2330]: __ Status: Subsequent run after boot.
Jun 10 17:39:08 host sdwdate[2330]: __ Static Time Sanity Check: Within minimum time 'Fri Feb 18 00:00:00 UTC 2022' and expiration timestamp 'Tue May 17 10:00:00 UTC 2033', ok.
Jun 10 17:39:08 host sdwdate[2330]: __ Tor Bootstrap Result:
Jun 10 17:39:08 host sdwdate[2330]: check_bootstrap_helper_script: /usr/bin/tor-circuit-established-check
Jun 10 17:39:08 host sdwdate[2330]: tor_bootstrap_timeout_type:
Jun 10 17:39:08 host sdwdate[2330]: tor_circuit_established_check_exit_code: 124
Jun 10 17:39:08 host sdwdate[2330]: __ ### END: ### Exiting with exit_code '1' indicating 'wait, show error icon and retry.'.
Jun 10 17:39:08 host sdwdate[2330]: 2022-06-10 17:39:08 - sdwdate - INFO - PREPARATION RESULT: (known) ERROR.
Jun 10 17:39:08 host sdwdate[2330]: 2022-06-10 17:39:08 - sdwdate - INFO -
Jun 10 17:39:10 host sdwdate[2330]: 2022-06-10 17:39:10 - sdwdate - INFO - PREPARATION:
Jun 10 17:39:10 host sdwdate[2330]: 2022-06-10 17:39:10 - sdwdate - INFO - __ ### START: ### /usr/libexec/helper-scripts/onion-time-pre-script
Jun 10 17:39:10 host sdwdate[2330]: __ Status: Subsequent run after boot.
Jun 10 17:39:10 host sdwdate[2330]: __ Static Time Sanity Check: Within minimum time 'Fri Feb 18 00:00:00 UTC 2022' and expiration timestamp 'Tue May 17 10:00:00 UTC 2033', ok.
Jun 10 17:39:10 host sdwdate[2330]: __ Tor reports: NOTICE BOOTSTRAP PROGRESS=100 TAG=done SUMMARY="Done"
Jun 10 17:39:10 host sdwdate[2330]: __ Tor circuit: established
Jun 10 17:39:10 host sdwdate[2330]: __ Tor Consensus Time Sanity Check: Clock within consensus parameters consensus/valid-after 2022-06-10 17:00:00 and consensus/valid-until 2022-06-10 20:00:00.
Jun 10 17:39:10 host sdwdate[2330]: __ Conclusion: Tor already reports circuit established.
Jun 10 17:39:10 host sdwdate[2330]: __ ### END: ### Exiting with exit_code '0' indicating 'success'.
Jun 10 17:39:10 host sdwdate[2330]: 2022-06-10 17:39:10 - sdwdate - INFO - PREPARATION RESULT: SUCCESS.
Jun 10 17:39:10 host sdwdate[2330]: 2022-06-10 17:39:10 - sdwdate - INFO -
Jun 10 17:39:10 host systemd[1]: Stopping User Manager for UID 0...
Jun 10 17:39:10 host systemd[2088]: Stopped target Main User Target.
Jun 10 17:39:10 host systemd[2088]: usertest.service: Succeeded.
Jun 10 17:39:10 host systemd[2088]: Stopped User Test Systemd Unit File.
Jun 10 17:39:10 host systemd[2088]: Stopped target Basic System.
Jun 10 17:39:10 host systemd[2088]: Stopped target Paths.
Jun 10 17:39:10 host systemd[2088]: Stopped target Sockets.
Jun 10 17:39:10 host systemd[2088]: Stopped target Timers.
Jun 10 17:39:10 host systemd[2088]: dirmngr.socket: Succeeded.
Jun 10 17:39:10 host systemd[2088]: Closed GnuPG network certificate management daemon.
Jun 10 17:39:10 host systemd[2088]: gpg-agent-browser.socket: Succeeded.
Jun 10 17:39:10 host systemd[2088]: Closed GnuPG cryptographic agent and passphrase cache (access for web browsers).
Jun 10 17:39:10 host systemd[2088]: gpg-agent-extra.socket: Succeeded.
Jun 10 17:39:10 host systemd[2088]: Closed GnuPG cryptographic agent and passphrase cache (restricted).
Jun 10 17:39:10 host systemd[2088]: gpg-agent-ssh.socket: Succeeded.
Jun 10 17:39:10 host systemd[2088]: Closed GnuPG cryptographic agent (ssh-agent emulation).
Jun 10 17:39:10 host systemd[2088]: gpg-agent.socket: Succeeded.
Jun 10 17:39:10 host systemd[2088]: Closed GnuPG cryptographic agent and passphrase cache.
Jun 10 17:39:10 host systemd[2088]: Removed slice User Application Slice.
Jun 10 17:39:10 host systemd[2088]: Reached target Shutdown.
Jun 10 17:39:10 host systemd[2088]: systemd-exit.service: Succeeded.
Jun 10 17:39:10 host systemd[2088]: Finished Exit the Session.
Jun 10 17:39:10 host systemd[2088]: Reached target Exit the Session.
Jun 10 17:39:10 host systemd[1]: user@0.service: Succeeded.
Jun 10 17:39:10 host systemd[1]: Stopped User Manager for UID 0.
Jun 10 17:39:10 host systemd[1]: Stopping User Runtime Directory /run/user/0...
Jun 10 17:39:10 host sdwdate[2330]: 2022-06-10 17:39:10 - sdwdate - INFO - Initial time fetching in progress...
Jun 10 17:39:10 host sdwdate[2330]: 2022-06-10 17:39:10 - sdwdate - INFO - Running sdwdate fetch loop. iteration: 1
Jun 10 17:39:10 host sdwdate[2330]: 2022-06-10 17:39:10 - sdwdate - INFO - pool 0: pool_size: 18 url_index: 10 already_picked_number: 1 already_picked_index: [10]
Jun 10 17:39:10 host sdwdate[2330]: 2022-06-10 17:39:10 - sdwdate - INFO - pool 1: pool_size: 18 url_index: 5 already_picked_number: 1 already_picked_index: [5]
Jun 10 17:39:10 host sdwdate[2330]: 2022-06-10 17:39:10 - sdwdate - INFO - pool 2: pool_size: 25 url_index: 17 already_picked_number: 1 already_picked_index: [17]
Jun 10 17:39:10 host sdwdate[2330]: 2022-06-10 17:39:10 - sdwdate - INFO - requested urls ['http://stormwayszuh4juycoy4kwoww5gvcu2c4tdtpkup667pdwe4qenzwayd.onion', 'https://27m3p2uv7igmj6kvd4ql3cct5h3sdwrsajovkkndeufumzyfhlfev4qd.onion', 'http://xpxduj55x2j27l2qytu2tcetykyfxbjbafin3x4i3ywddzphkbrd3jyd.onion']
Jun 10 17:39:10 host sdwdate[2330]: remote_times.py: url_to_unixtime_command (s):
Jun 10 17:39:10 host sdwdate[2330]: url_to_unixtime 127.0.0.1 9108 http://stormwayszuh4juycoy4kwoww5gvcu2c4tdtpkup667pdwe4qenzwayd.onion 80 true
Jun 10 17:39:10 host sdwdate[2330]: url_to_unixtime 127.0.0.1 9108 https://27m3p2uv7igmj6kvd4ql3cct5h3sdwrsajovkkndeufumzyfhlfev4qd.onion 80 true
Jun 10 17:39:10 host sdwdate[2330]: url_to_unixtime 127.0.0.1 9108 http://xpxduj55x2j27l2qytu2tcetykyfxbjbafin3x4i3ywddzphkbrd3jyd.onion 80 true
Jun 10 17:39:10 host systemd[1]: run-user-0.mount: Succeeded.
Jun 10 17:39:10 host systemd[1087]: run-user-0.mount: Succeeded.
Jun 10 17:39:10 host systemd[1]: user-runtime-dir@0.service: Succeeded.
Jun 10 17:39:10 host systemd[1]: Stopped User Runtime Directory /run/user/0.
Jun 10 17:39:10 host systemd[1]: Removed slice User Slice of UID 0.
Jun 10 17:39:18 host sudo[2576]:     user : PWD=/home/user ; USER=root ; COMMAND=/usr/bin/journalctl
Jun 10 17:39:18 host sudo[2576]: pam_unix(sudo:session): session opened for user root(uid=0) by (uid=1000)
Jun 10 17:39:24 host sudo[2576]: pam_unix(sudo:session): session closed for user root
Jun 10 17:40:06 host sdwdate[2330]: remote_times.py: i: 0 | done
Jun 10 17:40:13 host sdwdate[2330]: remote_times.py: i: 2 | done
Jun 10 17:40:17 host sdwdate[2330]: remote_times.py: i: 1 | done
Jun 10 17:40:17 host sdwdate[2330]: remote 0: http://stormwayszuh4juycoy4kwoww5gvcu2c4tdtpkup667pdwe4qenzwayd.onion
Jun 10 17:40:17 host sdwdate[2330]: * comment: https://web.archive.org/web/20210604190703/https://cryptostorm.is/
Jun 10 17:40:17 host sdwdate[2330]: * took_time     : 56.03 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * half_took_time: 28.02 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * replay_protection_unixtime: 1654882618
Jun 10 17:40:17 host sdwdate[2330]: * remote_unixtime           : 1654883442
Jun 10 17:40:17 host sdwdate[2330]: * consensus/valid-after           : 2022-06-10 17:00:00
Jun 10 17:40:17 host sdwdate[2330]: * replay_protection_time          : 2022-06-10 17:38:38
Jun 10 17:40:17 host sdwdate[2330]: * remote_time                     : 2022-06-10 17:50:42
Jun 10 17:40:17 host sdwdate[2330]: * consensus/valid-until           : 2022-06-10 20:00:00
Jun 10 17:40:17 host sdwdate[2330]: * time_diff_raw        : 636 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * time_diff_lag_cleaned: 607.98 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * Time Replay Protection         : sane
Jun 10 17:40:17 host sdwdate[2330]: * Tor Consensus Time Sanity Check: sane
Jun 10 17:40:17 host sdwdate[2330]: * remote_status: True
Jun 10 17:40:17 host sdwdate[2330]: remote 1: https://27m3p2uv7igmj6kvd4ql3cct5h3sdwrsajovkkndeufumzyfhlfev4qd.onion
Jun 10 17:40:17 host sdwdate[2330]: * comment: https://web.archive.org/web/20210604191739/https://securityheaders.com/?q=https%3A%2F%2Ftheintercept.com%2F&amp;followRedirects=on
Jun 10 17:40:17 host sdwdate[2330]: * took_time     : 66.96 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * half_took_time: 33.48 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * replay_protection_unixtime: 1654882618
Jun 10 17:40:17 host sdwdate[2330]: * remote_unixtime           : 1654883452
Jun 10 17:40:17 host sdwdate[2330]: * consensus/valid-after           : 2022-06-10 17:00:00
Jun 10 17:40:17 host sdwdate[2330]: * replay_protection_time          : 2022-06-10 17:38:38
Jun 10 17:40:17 host sdwdate[2330]: * remote_time                     : 2022-06-10 17:50:52
Jun 10 17:40:17 host sdwdate[2330]: * consensus/valid-until           : 2022-06-10 20:00:00
Jun 10 17:40:17 host sdwdate[2330]: * time_diff_raw        : 635 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * time_diff_lag_cleaned: 601.52 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * Time Replay Protection         : sane
Jun 10 17:40:17 host sdwdate[2330]: * Tor Consensus Time Sanity Check: sane
Jun 10 17:40:17 host sdwdate[2330]: * remote_status: True
Jun 10 17:40:17 host sdwdate[2330]: remote 2: http://xpxduj55x2j27l2qytu2tcetykyfxbjbafin3x4i3ywddzphkbrd3jyd.onion
Jun 10 17:40:17 host sdwdate[2330]: * comment: https://web.archive.org/web/20201231233846/https://theintercept.com/source/ https://theintercept.com/source/ The Intercept(securedrop)
Jun 10 17:40:17 host sdwdate[2330]: * took_time     : 62.72 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * half_took_time: 31.36 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * replay_protection_unixtime: 1654882618
Jun 10 17:40:17 host sdwdate[2330]: * remote_unixtime           : 1654883450
Jun 10 17:40:17 host sdwdate[2330]: * consensus/valid-after           : 2022-06-10 17:00:00
Jun 10 17:40:17 host sdwdate[2330]: * replay_protection_time          : 2022-06-10 17:38:38
Jun 10 17:40:17 host sdwdate[2330]: * remote_time                     : 2022-06-10 17:50:50
Jun 10 17:40:17 host sdwdate[2330]: * consensus/valid-until           : 2022-06-10 20:00:00
Jun 10 17:40:17 host sdwdate[2330]: * time_diff_raw        : 637 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * time_diff_lag_cleaned: 605.64 second(s)
Jun 10 17:40:17 host sdwdate[2330]: * Time Replay Protection         : sane
Jun 10 17:40:17 host sdwdate[2330]: * Tor Consensus Time Sanity Check: sane
Jun 10 17:40:17 host sdwdate[2330]: * remote_status: True
Jun 10 17:40:17 host sdwdate[2330]: remote_times.py: urls_list:
Jun 10 17:40:17 host sdwdate[2330]: ['http://stormwayszuh4juycoy4kwoww5gvcu2c4tdtpkup667pdwe4qenzwayd.onion', 'https://27m3p2uv7igmj6kvd4ql3cct5h3sdwrsajovkkndeufumzyfhlfev4qd.onion', 'http://xpxduj55x2j27l2qytu2tcetykyfxbjbafin3x4i3ywddzphkbrd3jyd.onion']
Jun 10 17:40:17 host sdwdate[2330]: remote_times.py: status_list:
Jun 10 17:40:17 host sdwdate[2330]: ['ok', 'ok', 'ok']
Jun 10 17:40:17 host sdwdate[2330]: remote_times.py: took_time_list:
Jun 10 17:40:17 host sdwdate[2330]: [56.03, 66.96, 62.72]
Jun 10 17:40:17 host sdwdate[2330]: remote_times.py: half_took_time_list:
Jun 10 17:40:17 host sdwdate[2330]: [28.02, 33.48, 31.36]
Jun 10 17:40:17 host sdwdate[2330]: remote_times.py: remote_unixtime_list:
Jun 10 17:40:17 host sdwdate[2330]: [1654883442, 1654883452, 1654883450]
Jun 10 17:40:17 host sdwdate[2330]: remote_times.py: time_diff_raw_int_list:
Jun 10 17:40:17 host sdwdate[2330]: [636, 635, 637]
Jun 10 17:40:17 host sdwdate[2330]: remote_times.py: time_diff_lag_cleaned_float_list:
Jun 10 17:40:17 host sdwdate[2330]: [607.98, 601.52, 605.64]
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - returned urls "['http://stormwayszuh4juycoy4kwoww5gvcu2c4tdtpkup667pdwe4qenzwayd.onion', 'https://27m3p2uv7igmj6kvd4ql3cct5h3sdwrsajovkkndeufumzyfhlfev4qd.onion', 'http://xpxduj55x2j27l2qytu2tcetykyfxbjbafin3x4i3ywddzphkbrd3jyd.onion']"
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO -
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - failed_urls: 0 allowed_failures: 6
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - pool 0: http://stormwayszuh4juycoy4kwoww5gvcu2c4tdtpkup667pdwe4qenzwayd.onion, web_time: 2022-06-10 17:50:42, took_time: 56.03 seconds, time_diff_raw: 636 seconds, time_diff_lag_cleaned: 608 seconds
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - pool 1: https://27m3p2uv7igmj6kvd4ql3cct5h3sdwrsajovkkndeufumzyfhlfev4qd.onion, web_time: 2022-06-10 17:50:52, took_time: 66.96 seconds, time_diff_raw: 635 seconds, time_diff_lag_cleaned: 602 seconds
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - pool 2: http://xpxduj55x2j27l2qytu2tcetykyfxbjbafin3x4i3ywddzphkbrd3jyd.onion, web_time: 2022-06-10 17:50:50, took_time: 62.72 seconds, time_diff_raw: 637 seconds, time_diff_lag_cleaned: 606 seconds
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - End fetching remote times.
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO -
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - Success.
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO -      request_took_times, sorted: [56.03, 62.72, 66.96]
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - request_half_took_times, sorted: [28.02, 31.36, 33.48]
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO -           time_diff_raw, sorted: [635, 636, 637]
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO -       diffs_lag_cleaned, sorted: [602, 606, 608]
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - median          request_took_times: +62.72
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - median     half_request_took_times: +31.36
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - median         raw time difference: +636.00
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - median lag_cleaned time difference: +606.00
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - Randomizing nanoseconds.
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - randomize                         : -0.953909358
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - new time difference               : +635.046090642
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - replay_protection_unixtime: 1654882618
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - old_unixtime              : 1654882817.644364357
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - new_unixtime              : 1654883452.690454960
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - replay_protection_time          : 2022-06-10 17:38:38
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - old_unixtime_human_readable     : 2022-06-10 17:40:18
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - new_unixtime_human_readable     : 2022-06-10 17:50:53
Jun 10 17:40:17 host sdwdate[2330]: 2022-06-10 17:40:17 - sdwdate - INFO - Instantly setting the time by using command: /bin/date --utc "+%Y-%m-%d %H:%M:%S" --set "@1654883452.690454960"
Jun 10 17:50:52 host sdwdate[2330]: 2022-06-10 17:50:52 - sdwdate - INFO - /bin/date output: 2022-06-10 17:50:52
Jun 10 17:50:52 host sdwdate[2330]: 2022-06-10 17:50:52 - sdwdate - INFO - Time Replay Protection: write 1654883453 to file: /var/lib/sdwdate/time-replay-protection-utc-unixtime
Jun 10 17:50:52 host sdwdate[2330]: 2022-06-10 17:50:52 - sdwdate - INFO - Time Replay Protection: write 2022-06-10 17:50:53 to file: /var/lib/sdwdate/time-replay-protection-utc-humanreadable
Jun 10 17:50:52 host sdwdate[2330]: 2022-06-10 17:50:52 - sdwdate - INFO - Sleeping for 85 minutes, ok.
</code></pre>
<p>Where:</p>
<pre><code class="lang-auto">Jun 10 17:38:58 host kernel: clocksource: timekeeping watchdog on CPU0: Marking clocksource 'tsc' as unstable because the skew is too large:
Jun 10 17:38:58 host kernel: clocksource:                       'xen' wd_now: f9d4b2a3a9 wd_last: 69052de169 mask: ffffffffffffffff
Jun 10 17:38:58 host kernel: clocksource:                       'tsc' cs_now: 8ab2519683 cs_last: 8a5c9b64e0 mask: ffffffffffffffff
Jun 10 17:38:58 host kernel: tsc: Marking TSC unstable due to clocksource watchdog
Jun 10 17:38:58 host kernel: clocksource: Checking clocksource tsc synchronization from CPU 0.
Jun 10 17:38:58 host kernel: clocksource: Override clocksource tsc is unstable and not HRT compatible - cannot switch while in HRT/NOHZ mode
Jun 10 17:38:58 host kernel: clocksource: Switched to clocksource xen
</code></pre>
<p>The clock is changed to xen after resume because tsc unreliable.</p>
          <p><a href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/5">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/5</link>
        <pubDate>Fri, 10 Jun 2022 19:52:19 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-13759-5</guid>
        <source url="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss">sys-whonix (sdwdate) not properly resuming from suspend</source>
      </item>
      <item>
        <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
        <dc:creator><![CDATA[marmarek]]></dc:creator>
        <description><![CDATA[
            <p>But even on first resume, it doesn‚Äôt result in swapping / 100%CPU in sys-firewall, right? There must be some specific interaction with Whonix that makes it this bad (my bet is on sdwdate).</p>
<p>I <em>think</em> it should be fixed with <a href="https://github.com/QubesOS/qubes-core-admin/pull/473" class="inline-onebox" rel="noopener nofollow ugc">Properly suspend all VMs, not only those with PCI devices by marmarek ¬∑ Pull Request #473 ¬∑ QubesOS/qubes-core-admin ¬∑ GitHub</a>, but there are a couple of prerequisites for this change (see PR description). In the meantime, I think it‚Äôs time to revert to <code>clocksource=xen</code>.</p>
          <p><a href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/4">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/4</link>
        <pubDate>Fri, 10 Jun 2022 19:20:51 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-13759-4</guid>
        <source url="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss">sys-whonix (sdwdate) not properly resuming from suspend</source>
      </item>
      <item>
        <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
        <dc:creator><![CDATA[tlaurion]]></dc:creator>
        <description><![CDATA[
            <p>The current issue also affects sys-firewall and sys-net, but after the first boot issue, available clocksources do not contain tsc anymore, only xen.</p>
<p>So the issue happens only on first resume path of each boot. Maybe that is why not everyone is getting crazy on this issue?</p>
          <p><a href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/3">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/3</link>
        <pubDate>Fri, 10 Jun 2022 19:03:34 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-13759-3</guid>
        <source url="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss">sys-whonix (sdwdate) not properly resuming from suspend</source>
      </item>
      <item>
        <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
        <dc:creator><![CDATA[tlaurion]]></dc:creator>
        <description><![CDATA[
            <p>under sys-whonix:</p>
<pre><code>echo xen &gt; /sys/devices/system/clocksource/clocksource0/current_clocksource
</code></pre>
<p>Fixes the issue. Troubleshooted with <a class="mention" href="http://forums.whonix.org/u/marmarek">@marmarek</a>.</p>
<p>tsc is not a right clock source for the moment. To have tsc right, some tasks need to be done first:</p>
<aside class="onebox githubpullrequest" data-onebox-src="https://github.com/QubesOS/qubes-core-admin/pull/473">
  <header class="source">

      <a href="https://github.com/QubesOS/qubes-core-admin/pull/473" target="_blank" rel="noopener nofollow ugc">github.com/QubesOS/qubes-core-admin</a>
  </header>

  <article class="onebox-body">
    <div class="github-row">
  <div class="github-icon-container" title="Pull Request">
    <svg width="60" height="60" class="github-icon" viewBox="0 0 12 16" aria-hidden="true"><path d="M11 11.28V5c-.03-.78-.34-1.47-.94-2.06C9.46 2.35 8.78 2.03 8 2H7V0L4 3l3 3V4h1c.27.02.48.11.69.31.21.2.3.42.31.69v6.28A1.993 1.993 0 0 0 10 15a1.993 1.993 0 0 0 1-3.72zm-1 2.92c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zM4 3c0-1.11-.89-2-2-2a1.993 1.993 0 0 0-1 3.72v6.56A1.993 1.993 0 0 0 2 15a1.993 1.993 0 0 0 1-3.72V4.72c.59-.34 1-.98 1-1.72zm-.8 10c0 .66-.55 1.2-1.2 1.2-.65 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"></path></svg>
  </div>

  <div class="github-info-container">
    <h4>
      <a href="https://github.com/QubesOS/qubes-core-admin/pull/473" target="_blank" rel="noopener nofollow ugc">Properly suspend all VMs, not only those with PCI devices</a>
    </h4>

    <div class="branches">
      <code>QubesOS:master</code> ‚Üê <code>marmarek:suspend-all</code>
    </div>

    <div class="github-info">
      <div class="date">
        opened <span class="discourse-local-date" data-format="ll" data-date="2022-05-03" data-time="15:06:49" data-timezone="UTC">03:06PM - 03 May 22 UTC</span>
      </div>

      <div class="user">
        <a href="https://github.com/marmarek" target="_blank" rel="noopener nofollow ugc">
          <img alt="marmarek" src="https://avatars.githubusercontent.com/u/726704?v=4" class="onebox-avatar-inline" width="20" height="20">
          marmarek
        </a>
      </div>

      <div class="lines" title="1 commits changed 1 files with 5 additions and 8 deletions">
        <a href="https://github.com/QubesOS/qubes-core-admin/pull/473/files" target="_blank" rel="noopener nofollow ugc">
          <span class="added">+5</span>
          <span class="removed">-8</span>
        </a>
      </div>
    </div>
  </div>
</div>

  <div class="github-row">
    <p class="github-body-container">Just pausing a VM for a host suspend breaks 'tsc' clocksource.

QubesOS/qubes-<span class="show-more-container"><a href="https://github.com/QubesOS/qubes-core-admin/pull/473" target="_blank" rel="noopener nofollow ugc" class="show-more">‚Ä¶</a></span><span class="excerpt hidden">issues#7404
QubesOS/qubes-issues#2044

TODO:

- [ ] test with mirage PVH
- [ ] suspend (instead of pause) stubdomain too
- [ ] Fix QWT to not remove xenstore entry (https://github.com/QubesOS/qubes-issues/issues/7404#issuecomment-1117611495)</span></p>
  </div>

  </article>

  <div class="onebox-metadata">
    
    
  </div>

  <div style="clear: both"></div>
</aside>

<p>Whonix wanted to get rid of xen clock source:</p>
<p><a href="https://phabricator.whonix.org/T389" class="onebox" target="_blank" rel="noopener nofollow ugc">https://phabricator.whonix.org/T389</a></p>
<p>But for the moment, putting xen as exclusive clocksource would be the transient solution.</p>
          <p><a href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/2">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/2</link>
        <pubDate>Fri, 10 Jun 2022 18:36:28 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-13759-2</guid>
        <source url="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss">sys-whonix (sdwdate) not properly resuming from suspend</source>
      </item>
      <item>
        <title>sys-whonix (sdwdate) not properly resuming from suspend</title>
        <dc:creator><![CDATA[tlaurion]]></dc:creator>
        <description><![CDATA[
            <p>Hello there,</p>
<p>Qubes 4.1.<br>
sdwdate: 3:19.7-1</p>
<p>With all updates installed under whonix-gw-16, when the system wakes up from suspend, sys-whonix keeps a whole core at 100% CPU usage and Terminal opened prior of going into suspend are unresponsive. sdwdate-gui tor-control-panel can be opened, but trying to Restart Tor or any action happening there will freeze that window as well.</p>
<p>If I keep open a terminal to have top running, it doesn‚Äôt update anymore and timestamp is stuck to the time system suspended.</p>
<p>If I launch <code>qvm-run --no-gui --pass-io sys-whonix "ps fauxwwww"</code> I see that sdwdate‚Äôs invocation of <code>tor-circuit-established-check</code> is consuming more and more memory (90%) and then swapping is occuring, even though its parent is launching it through <code>timeout --kill-after=5s</code>, which never occurs. xen-balloning and <code>systemd --user</code> are also eating a lot of CPU. Traffic is not routed through tor.</p>
<p>Note that qvm-run calls are not always successful either, and <code>sudo killall sdwdate</code> or <code>sudo systemctl stop sdwdate</code> doesn‚Äôt reestablish windows availability, even though the processes disappeared.</p>
<p>Any debugging insights here?</p>
<p>Reinstalling whonix-gw-16 through <code>qvm-template reinstall whonix-gw-16</code> doesn‚Äôt show behavior, which is deploying sdwdate: 3:19.1-1. Upgrading whonix-gw-16 to latest exhibits those behaviors again.  Not sure the problem is directly linked to sdwdate.</p>
<p>Cloned whonix-gw-16 to whonix-gw-16_latest. Now trying to downgrade some packages to isolate the problem source.</p>
          <p><a href="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/1">Read full topic</a></p>
        ]]></description>
        <link>http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759/1</link>
        <pubDate>Fri, 10 Jun 2022 16:50:18 +0000</pubDate>
        <guid isPermaLink="false">forums.whonix.org-post-13759-1</guid>
        <source url="http://forums.whonix.org/t/sys-whonix-sdwdate-not-properly-resuming-from-suspend/13759.rss">sys-whonix (sdwdate) not properly resuming from suspend</source>
      </item>
  </channel>
</rss>
